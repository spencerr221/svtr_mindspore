# 1.This file shows the parsed IR info when graph evaluating failed to help find the problem.
# 2.You can search the last `------------------------>` to the node which is inferred failed.
# 3.Refer to https://www.mindspore.cn/search?inputValue=analyze_fail.dat to get more instructions.
# ===============================================================================

# [No.1] Default_wrapper.29
# In file /home/mindspore/anaconda3/envs/ms1.9/lib/python3.7/site-packages/mindspore/nn/wrap/cell_wrapper.py:379/    def construct(self, *inputs):/
funcgraph fg_29(
        %para1 : Tensor(F32)[64, 3, 64, 256]    # inputs0
        , %para2 : Tensor(I64)[64, 25]    # inputs1
        , %para3 : Ref[Tensor(F32)][32, 3, 3, 3]    # transform.stn_head.stn_convnet.0.0.weight
        , %para4 : Ref[Tensor(F32)][32]    # transform.stn_head.stn_convnet.0.1.gamma
        , %para5 : Ref[Tensor(F32)][32]    # transform.stn_head.stn_convnet.0.1.beta
        , %para6 : Ref[Tensor(F32)][64, 32, 3, 3]    # transform.stn_head.stn_convnet.2.0.weight
        , %para7 : Ref[Tensor(F32)][64]    # transform.stn_head.stn_convnet.2.1.gamma
        , %para8 : Ref[Tensor(F32)][64]    # transform.stn_head.stn_convnet.2.1.beta
        , %para9 : Ref[Tensor(F32)][128, 64, 3, 3]    # transform.stn_head.stn_convnet.4.0.weight
        , %para10 : Ref[Tensor(F32)][128]    # transform.stn_head.stn_convnet.4.1.gamma
        , %para11 : Ref[Tensor(F32)][128]    # transform.stn_head.stn_convnet.4.1.beta
        , %para12 : Ref[Tensor(F32)][256, 128, 3, 3]    # transform.stn_head.stn_convnet.6.0.weight
        , %para13 : Ref[Tensor(F32)][256]    # transform.stn_head.stn_convnet.6.1.gamma
        , %para14 : Ref[Tensor(F32)][256]    # transform.stn_head.stn_convnet.6.1.beta
        , %para15 : Ref[Tensor(F32)][256, 256, 3, 3]    # transform.stn_head.stn_convnet.8.0.weight
        , %para16 : Ref[Tensor(F32)][256]    # transform.stn_head.stn_convnet.8.1.gamma
        , %para17 : Ref[Tensor(F32)][256]    # transform.stn_head.stn_convnet.8.1.beta
        , %para18 : Ref[Tensor(F32)][256, 256, 3, 3]    # transform.stn_head.stn_convnet.10.0.weight
        , %para19 : Ref[Tensor(F32)][256]    # transform.stn_head.stn_convnet.10.1.gamma
        , %para20 : Ref[Tensor(F32)][256]    # transform.stn_head.stn_convnet.10.1.beta
        , %para21 : Ref[Tensor(F32)][512, 512]    # transform.stn_head.stn_fc1.0.weight
        , %para22 : Ref[Tensor(F32)][512]    # transform.stn_head.stn_fc1.0.bias
        , %para23 : Ref[Tensor(F32)][512]    # transform.stn_head.stn_fc1.1.gamma
        , %para24 : Ref[Tensor(F32)][512]    # transform.stn_head.stn_fc1.1.beta
        , %para25 : Ref[Tensor(F32)][40, 512]    # transform.stn_head.stn_fc2.weight
        , %para26 : Ref[Tensor(F32)][40]    # transform.stn_head.stn_fc2.bias
        , %para27 : Ref[Tensor(F32)][1, 200, 64]    # backbone.pos_embed
        , %para28 : Ref[Tensor(F32)][32, 3, 3, 3]    # backbone.patch_embed.proj.0.conv.weight
        , %para29 : Ref[Tensor(F32)][32]    # backbone.patch_embed.proj.0.norm.gamma
        , %para30 : Ref[Tensor(F32)][32]    # backbone.patch_embed.proj.0.norm.beta
        , %para31 : Ref[Tensor(F32)][64, 32, 3, 3]    # backbone.patch_embed.proj.1.conv.weight
        , %para32 : Ref[Tensor(F32)][64]    # backbone.patch_embed.proj.1.norm.gamma
        , %para33 : Ref[Tensor(F32)][64]    # backbone.patch_embed.proj.1.norm.beta
        , %para34 : Ref[Tensor(F32)][64]    # backbone.blocks1.0.norm1.gamma
        , %para35 : Ref[Tensor(F32)][64]    # backbone.blocks1.0.norm1.beta
        , %para36 : Ref[Tensor(F32)][192, 64]    # backbone.blocks1.0.mixer.qkv.weight
        , %para37 : Ref[Tensor(F32)][192]    # backbone.blocks1.0.mixer.qkv.bias
        , %para38 : Ref[Tensor(F32)][64, 64]    # backbone.blocks1.0.mixer.proj.weight
        , %para39 : Ref[Tensor(F32)][64]    # backbone.blocks1.0.mixer.proj.bias
        , %para40 : Ref[Tensor(F32)][64]    # backbone.blocks1.0.norm2.gamma
        , %para41 : Ref[Tensor(F32)][64]    # backbone.blocks1.0.norm2.beta
        , %para42 : Ref[Tensor(F32)][256, 64]    # backbone.blocks1.0.mlp.fc1.weight
        , %para43 : Ref[Tensor(F32)][256]    # backbone.blocks1.0.mlp.fc1.bias
        , %para44 : Ref[Tensor(F32)][64, 256]    # backbone.blocks1.0.mlp.fc2.weight
        , %para45 : Ref[Tensor(F32)][64]    # backbone.blocks1.0.mlp.fc2.bias
        , %para46 : Ref[Tensor(F32)][64]    # backbone.blocks1.1.norm1.gamma
        , %para47 : Ref[Tensor(F32)][64]    # backbone.blocks1.1.norm1.beta
        , %para48 : Ref[Tensor(F32)][192, 64]    # backbone.blocks1.1.mixer.qkv.weight
        , %para49 : Ref[Tensor(F32)][192]    # backbone.blocks1.1.mixer.qkv.bias
        , %para50 : Ref[Tensor(F32)][64, 64]    # backbone.blocks1.1.mixer.proj.weight
        , %para51 : Ref[Tensor(F32)][64]    # backbone.blocks1.1.mixer.proj.bias
        , %para52 : Ref[Tensor(F32)][64]    # backbone.blocks1.1.norm2.gamma
        , %para53 : Ref[Tensor(F32)][64]    # backbone.blocks1.1.norm2.beta
        , %para54 : Ref[Tensor(F32)][256, 64]    # backbone.blocks1.1.mlp.fc1.weight
        , %para55 : Ref[Tensor(F32)][256]    # backbone.blocks1.1.mlp.fc1.bias
        , %para56 : Ref[Tensor(F32)][64, 256]    # backbone.blocks1.1.mlp.fc2.weight
        , %para57 : Ref[Tensor(F32)][64]    # backbone.blocks1.1.mlp.fc2.bias
        , %para58 : Ref[Tensor(F32)][64]    # backbone.blocks1.2.norm1.gamma
        , %para59 : Ref[Tensor(F32)][64]    # backbone.blocks1.2.norm1.beta
        , %para60 : Ref[Tensor(F32)][192, 64]    # backbone.blocks1.2.mixer.qkv.weight
        , %para61 : Ref[Tensor(F32)][192]    # backbone.blocks1.2.mixer.qkv.bias
        , %para62 : Ref[Tensor(F32)][64, 64]    # backbone.blocks1.2.mixer.proj.weight
        , %para63 : Ref[Tensor(F32)][64]    # backbone.blocks1.2.mixer.proj.bias
        , %para64 : Ref[Tensor(F32)][64]    # backbone.blocks1.2.norm2.gamma
        , %para65 : Ref[Tensor(F32)][64]    # backbone.blocks1.2.norm2.beta
        , %para66 : Ref[Tensor(F32)][256, 64]    # backbone.blocks1.2.mlp.fc1.weight
        , %para67 : Ref[Tensor(F32)][256]    # backbone.blocks1.2.mlp.fc1.bias
        , %para68 : Ref[Tensor(F32)][64, 256]    # backbone.blocks1.2.mlp.fc2.weight
        , %para69 : Ref[Tensor(F32)][64]    # backbone.blocks1.2.mlp.fc2.bias
        , %para70 : Ref[Tensor(F32)][128, 64, 3, 3]    # backbone.sub_sample1.conv.weight
        , %para71 : Ref[Tensor(F32)][128]    # backbone.sub_sample1.norm.gamma
        , %para72 : Ref[Tensor(F32)][128]    # backbone.sub_sample1.norm.beta
        , %para73 : Ref[Tensor(F32)][128]    # backbone.blocks2.0.norm1.gamma
        , %para74 : Ref[Tensor(F32)][128]    # backbone.blocks2.0.norm1.beta
        , %para75 : Ref[Tensor(F32)][384, 128]    # backbone.blocks2.0.mixer.qkv.weight
        , %para76 : Ref[Tensor(F32)][384]    # backbone.blocks2.0.mixer.qkv.bias
        , %para77 : Ref[Tensor(F32)][128, 128]    # backbone.blocks2.0.mixer.proj.weight
        , %para78 : Ref[Tensor(F32)][128]    # backbone.blocks2.0.mixer.proj.bias
        , %para79 : Ref[Tensor(F32)][128]    # backbone.blocks2.0.norm2.gamma
        , %para80 : Ref[Tensor(F32)][128]    # backbone.blocks2.0.norm2.beta
        , %para81 : Ref[Tensor(F32)][512, 128]    # backbone.blocks2.0.mlp.fc1.weight
        , %para82 : Ref[Tensor(F32)][512]    # backbone.blocks2.0.mlp.fc1.bias
        , %para83 : Ref[Tensor(F32)][128, 512]    # backbone.blocks2.0.mlp.fc2.weight
        , %para84 : Ref[Tensor(F32)][128]    # backbone.blocks2.0.mlp.fc2.bias
        , %para85 : Ref[Tensor(F32)][128]    # backbone.blocks2.1.norm1.gamma
        , %para86 : Ref[Tensor(F32)][128]    # backbone.blocks2.1.norm1.beta
        , %para87 : Ref[Tensor(F32)][384, 128]    # backbone.blocks2.1.mixer.qkv.weight
        , %para88 : Ref[Tensor(F32)][384]    # backbone.blocks2.1.mixer.qkv.bias
        , %para89 : Ref[Tensor(F32)][128, 128]    # backbone.blocks2.1.mixer.proj.weight
        , %para90 : Ref[Tensor(F32)][128]    # backbone.blocks2.1.mixer.proj.bias
        , %para91 : Ref[Tensor(F32)][128]    # backbone.blocks2.1.norm2.gamma
        , %para92 : Ref[Tensor(F32)][128]    # backbone.blocks2.1.norm2.beta
        , %para93 : Ref[Tensor(F32)][512, 128]    # backbone.blocks2.1.mlp.fc1.weight
        , %para94 : Ref[Tensor(F32)][512]    # backbone.blocks2.1.mlp.fc1.bias
        , %para95 : Ref[Tensor(F32)][128, 512]    # backbone.blocks2.1.mlp.fc2.weight
        , %para96 : Ref[Tensor(F32)][128]    # backbone.blocks2.1.mlp.fc2.bias
        , %para97 : Ref[Tensor(F32)][128]    # backbone.blocks2.2.norm1.gamma
        , %para98 : Ref[Tensor(F32)][128]    # backbone.blocks2.2.norm1.beta
        , %para99 : Ref[Tensor(F32)][384, 128]    # backbone.blocks2.2.mixer.qkv.weight
        , %para100 : Ref[Tensor(F32)][384]    # backbone.blocks2.2.mixer.qkv.bias
        , %para101 : Ref[Tensor(F32)][128, 128]    # backbone.blocks2.2.mixer.proj.weight
        , %para102 : Ref[Tensor(F32)][128]    # backbone.blocks2.2.mixer.proj.bias
        , %para103 : Ref[Tensor(F32)][128]    # backbone.blocks2.2.norm2.gamma
        , %para104 : Ref[Tensor(F32)][128]    # backbone.blocks2.2.norm2.beta
        , %para105 : Ref[Tensor(F32)][512, 128]    # backbone.blocks2.2.mlp.fc1.weight
        , %para106 : Ref[Tensor(F32)][512]    # backbone.blocks2.2.mlp.fc1.bias
        , %para107 : Ref[Tensor(F32)][128, 512]    # backbone.blocks2.2.mlp.fc2.weight
        , %para108 : Ref[Tensor(F32)][128]    # backbone.blocks2.2.mlp.fc2.bias
        , %para109 : Ref[Tensor(F32)][128]    # backbone.blocks2.3.norm1.gamma
        , %para110 : Ref[Tensor(F32)][128]    # backbone.blocks2.3.norm1.beta
        , %para111 : Ref[Tensor(F32)][384, 128]    # backbone.blocks2.3.mixer.qkv.weight
        , %para112 : Ref[Tensor(F32)][384]    # backbone.blocks2.3.mixer.qkv.bias
        , %para113 : Ref[Tensor(F32)][128, 128]    # backbone.blocks2.3.mixer.proj.weight
        , %para114 : Ref[Tensor(F32)][128]    # backbone.blocks2.3.mixer.proj.bias
        , %para115 : Ref[Tensor(F32)][128]    # backbone.blocks2.3.norm2.gamma
        , %para116 : Ref[Tensor(F32)][128]    # backbone.blocks2.3.norm2.beta
        , %para117 : Ref[Tensor(F32)][512, 128]    # backbone.blocks2.3.mlp.fc1.weight
        , %para118 : Ref[Tensor(F32)][512]    # backbone.blocks2.3.mlp.fc1.bias
        , %para119 : Ref[Tensor(F32)][128, 512]    # backbone.blocks2.3.mlp.fc2.weight
        , %para120 : Ref[Tensor(F32)][128]    # backbone.blocks2.3.mlp.fc2.bias
        , %para121 : Ref[Tensor(F32)][128]    # backbone.blocks2.4.norm1.gamma
        , %para122 : Ref[Tensor(F32)][128]    # backbone.blocks2.4.norm1.beta
        , %para123 : Ref[Tensor(F32)][384, 128]    # backbone.blocks2.4.mixer.qkv.weight
        , %para124 : Ref[Tensor(F32)][384]    # backbone.blocks2.4.mixer.qkv.bias
        , %para125 : Ref[Tensor(F32)][128, 128]    # backbone.blocks2.4.mixer.proj.weight
        , %para126 : Ref[Tensor(F32)][128]    # backbone.blocks2.4.mixer.proj.bias
        , %para127 : Ref[Tensor(F32)][128]    # backbone.blocks2.4.norm2.gamma
        , %para128 : Ref[Tensor(F32)][128]    # backbone.blocks2.4.norm2.beta
        , %para129 : Ref[Tensor(F32)][512, 128]    # backbone.blocks2.4.mlp.fc1.weight
        , %para130 : Ref[Tensor(F32)][512]    # backbone.blocks2.4.mlp.fc1.bias
        , %para131 : Ref[Tensor(F32)][128, 512]    # backbone.blocks2.4.mlp.fc2.weight
        , %para132 : Ref[Tensor(F32)][128]    # backbone.blocks2.4.mlp.fc2.bias
        , %para133 : Ref[Tensor(F32)][128]    # backbone.blocks2.5.norm1.gamma
        , %para134 : Ref[Tensor(F32)][128]    # backbone.blocks2.5.norm1.beta
        , %para135 : Ref[Tensor(F32)][384, 128]    # backbone.blocks2.5.mixer.qkv.weight
        , %para136 : Ref[Tensor(F32)][384]    # backbone.blocks2.5.mixer.qkv.bias
        , %para137 : Ref[Tensor(F32)][128, 128]    # backbone.blocks2.5.mixer.proj.weight
        , %para138 : Ref[Tensor(F32)][128]    # backbone.blocks2.5.mixer.proj.bias
        , %para139 : Ref[Tensor(F32)][128]    # backbone.blocks2.5.norm2.gamma
        , %para140 : Ref[Tensor(F32)][128]    # backbone.blocks2.5.norm2.beta
        , %para141 : Ref[Tensor(F32)][512, 128]    # backbone.blocks2.5.mlp.fc1.weight
        , %para142 : Ref[Tensor(F32)][512]    # backbone.blocks2.5.mlp.fc1.bias
        , %para143 : Ref[Tensor(F32)][128, 512]    # backbone.blocks2.5.mlp.fc2.weight
        , %para144 : Ref[Tensor(F32)][128]    # backbone.blocks2.5.mlp.fc2.bias
        , %para145 : Ref[Tensor(F32)][256, 128, 3, 3]    # backbone.sub_sample2.conv.weight
        , %para146 : Ref[Tensor(F32)][256]    # backbone.sub_sample2.norm.gamma
        , %para147 : Ref[Tensor(F32)][256]    # backbone.sub_sample2.norm.beta
        , %para148 : Ref[Tensor(F32)][256]    # backbone.blocks3.0.norm1.gamma
        , %para149 : Ref[Tensor(F32)][256]    # backbone.blocks3.0.norm1.beta
        , %para150 : Ref[Tensor(F32)][768, 256]    # backbone.blocks3.0.mixer.qkv.weight
        , %para151 : Ref[Tensor(F32)][768]    # backbone.blocks3.0.mixer.qkv.bias
        , %para152 : Ref[Tensor(F32)][256, 256]    # backbone.blocks3.0.mixer.proj.weight
        , %para153 : Ref[Tensor(F32)][256]    # backbone.blocks3.0.mixer.proj.bias
        , %para154 : Ref[Tensor(F32)][256]    # backbone.blocks3.0.norm2.gamma
        , %para155 : Ref[Tensor(F32)][256]    # backbone.blocks3.0.norm2.beta
        , %para156 : Ref[Tensor(F32)][1024, 256]    # backbone.blocks3.0.mlp.fc1.weight
        , %para157 : Ref[Tensor(F32)][1024]    # backbone.blocks3.0.mlp.fc1.bias
        , %para158 : Ref[Tensor(F32)][256, 1024]    # backbone.blocks3.0.mlp.fc2.weight
        , %para159 : Ref[Tensor(F32)][256]    # backbone.blocks3.0.mlp.fc2.bias
        , %para160 : Ref[Tensor(F32)][256]    # backbone.blocks3.1.norm1.gamma
        , %para161 : Ref[Tensor(F32)][256]    # backbone.blocks3.1.norm1.beta
        , %para162 : Ref[Tensor(F32)][768, 256]    # backbone.blocks3.1.mixer.qkv.weight
        , %para163 : Ref[Tensor(F32)][768]    # backbone.blocks3.1.mixer.qkv.bias
        , %para164 : Ref[Tensor(F32)][256, 256]    # backbone.blocks3.1.mixer.proj.weight
        , %para165 : Ref[Tensor(F32)][256]    # backbone.blocks3.1.mixer.proj.bias
        , %para166 : Ref[Tensor(F32)][256]    # backbone.blocks3.1.norm2.gamma
        , %para167 : Ref[Tensor(F32)][256]    # backbone.blocks3.1.norm2.beta
        , %para168 : Ref[Tensor(F32)][1024, 256]    # backbone.blocks3.1.mlp.fc1.weight
        , %para169 : Ref[Tensor(F32)][1024]    # backbone.blocks3.1.mlp.fc1.bias
        , %para170 : Ref[Tensor(F32)][256, 1024]    # backbone.blocks3.1.mlp.fc2.weight
        , %para171 : Ref[Tensor(F32)][256]    # backbone.blocks3.1.mlp.fc2.bias
        , %para172 : Ref[Tensor(F32)][256]    # backbone.blocks3.2.norm1.gamma
        , %para173 : Ref[Tensor(F32)][256]    # backbone.blocks3.2.norm1.beta
        , %para174 : Ref[Tensor(F32)][768, 256]    # backbone.blocks3.2.mixer.qkv.weight
        , %para175 : Ref[Tensor(F32)][768]    # backbone.blocks3.2.mixer.qkv.bias
        , %para176 : Ref[Tensor(F32)][256, 256]    # backbone.blocks3.2.mixer.proj.weight
        , %para177 : Ref[Tensor(F32)][256]    # backbone.blocks3.2.mixer.proj.bias
        , %para178 : Ref[Tensor(F32)][256]    # backbone.blocks3.2.norm2.gamma
        , %para179 : Ref[Tensor(F32)][256]    # backbone.blocks3.2.norm2.beta
        , %para180 : Ref[Tensor(F32)][1024, 256]    # backbone.blocks3.2.mlp.fc1.weight
        , %para181 : Ref[Tensor(F32)][1024]    # backbone.blocks3.2.mlp.fc1.bias
        , %para182 : Ref[Tensor(F32)][256, 1024]    # backbone.blocks3.2.mlp.fc2.weight
        , %para183 : Ref[Tensor(F32)][256]    # backbone.blocks3.2.mlp.fc2.bias
        , %para184 : Ref[Tensor(F32)][192, 256, 1, 1]    # backbone.last_conv.weight
        , %para185 : Ref[Tensor(F32)][256]    # backbone.norm.gamma
        , %para186 : Ref[Tensor(F32)][256]    # backbone.norm.beta
        , %para187 : Ref[Tensor(F32)][37, 192]    # head.fc.weight
        , %para188 : Ref[Tensor(F32)][37]    # head.fc.bias
        , %para189 : Ref[Tensor(F32)][32, 3, 3, 3]    # adam_m.transform.stn_head.stn_convnet.0.0.weight
        , %para190 : Ref[Tensor(F32)][32]    # adam_m.transform.stn_head.stn_convnet.0.1.gamma
        , %para191 : Ref[Tensor(F32)][32]    # adam_m.transform.stn_head.stn_convnet.0.1.beta
        , %para192 : Ref[Tensor(F32)][64, 32, 3, 3]    # adam_m.transform.stn_head.stn_convnet.2.0.weight
        , %para193 : Ref[Tensor(F32)][64]    # adam_m.transform.stn_head.stn_convnet.2.1.gamma
        , %para194 : Ref[Tensor(F32)][64]    # adam_m.transform.stn_head.stn_convnet.2.1.beta
        , %para195 : Ref[Tensor(F32)][128, 64, 3, 3]    # adam_m.transform.stn_head.stn_convnet.4.0.weight
        , %para196 : Ref[Tensor(F32)][128]    # adam_m.transform.stn_head.stn_convnet.4.1.gamma
        , %para197 : Ref[Tensor(F32)][128]    # adam_m.transform.stn_head.stn_convnet.4.1.beta
        , %para198 : Ref[Tensor(F32)][256, 128, 3, 3]    # adam_m.transform.stn_head.stn_convnet.6.0.weight
        , %para199 : Ref[Tensor(F32)][256]    # adam_m.transform.stn_head.stn_convnet.6.1.gamma
        , %para200 : Ref[Tensor(F32)][256]    # adam_m.transform.stn_head.stn_convnet.6.1.beta
        , %para201 : Ref[Tensor(F32)][256, 256, 3, 3]    # adam_m.transform.stn_head.stn_convnet.8.0.weight
        , %para202 : Ref[Tensor(F32)][256]    # adam_m.transform.stn_head.stn_convnet.8.1.gamma
        , %para203 : Ref[Tensor(F32)][256]    # adam_m.transform.stn_head.stn_convnet.8.1.beta
        , %para204 : Ref[Tensor(F32)][256, 256, 3, 3]    # adam_m.transform.stn_head.stn_convnet.10.0.weight
        , %para205 : Ref[Tensor(F32)][256]    # adam_m.transform.stn_head.stn_convnet.10.1.gamma
        , %para206 : Ref[Tensor(F32)][256]    # adam_m.transform.stn_head.stn_convnet.10.1.beta
        , %para207 : Ref[Tensor(F32)][512, 512]    # adam_m.transform.stn_head.stn_fc1.0.weight
        , %para208 : Ref[Tensor(F32)][512]    # adam_m.transform.stn_head.stn_fc1.0.bias
        , %para209 : Ref[Tensor(F32)][512]    # adam_m.transform.stn_head.stn_fc1.1.gamma
        , %para210 : Ref[Tensor(F32)][512]    # adam_m.transform.stn_head.stn_fc1.1.beta
        , %para211 : Ref[Tensor(F32)][40, 512]    # adam_m.transform.stn_head.stn_fc2.weight
        , %para212 : Ref[Tensor(F32)][40]    # adam_m.transform.stn_head.stn_fc2.bias
        , %para213 : Ref[Tensor(F32)][1, 200, 64]    # adam_m.backbone.pos_embed
        , %para214 : Ref[Tensor(F32)][32, 3, 3, 3]    # adam_m.backbone.patch_embed.proj.0.conv.weight
        , %para215 : Ref[Tensor(F32)][32]    # adam_m.backbone.patch_embed.proj.0.norm.gamma
        , %para216 : Ref[Tensor(F32)][32]    # adam_m.backbone.patch_embed.proj.0.norm.beta
        , %para217 : Ref[Tensor(F32)][64, 32, 3, 3]    # adam_m.backbone.patch_embed.proj.1.conv.weight
        , %para218 : Ref[Tensor(F32)][64]    # adam_m.backbone.patch_embed.proj.1.norm.gamma
        , %para219 : Ref[Tensor(F32)][64]    # adam_m.backbone.patch_embed.proj.1.norm.beta
        , %para220 : Ref[Tensor(F32)][64]    # adam_m.backbone.blocks1.0.norm1.gamma
        , %para221 : Ref[Tensor(F32)][64]    # adam_m.backbone.blocks1.0.norm1.beta
        , %para222 : Ref[Tensor(F32)][192, 64]    # adam_m.backbone.blocks1.0.mixer.qkv.weight
        , %para223 : Ref[Tensor(F32)][192]    # adam_m.backbone.blocks1.0.mixer.qkv.bias
        , %para224 : Ref[Tensor(F32)][64, 64]    # adam_m.backbone.blocks1.0.mixer.proj.weight
        , %para225 : Ref[Tensor(F32)][64]    # adam_m.backbone.blocks1.0.mixer.proj.bias
        , %para226 : Ref[Tensor(F32)][64]    # adam_m.backbone.blocks1.0.norm2.gamma
        , %para227 : Ref[Tensor(F32)][64]    # adam_m.backbone.blocks1.0.norm2.beta
        , %para228 : Ref[Tensor(F32)][256, 64]    # adam_m.backbone.blocks1.0.mlp.fc1.weight
        , %para229 : Ref[Tensor(F32)][256]    # adam_m.backbone.blocks1.0.mlp.fc1.bias
        , %para230 : Ref[Tensor(F32)][64, 256]    # adam_m.backbone.blocks1.0.mlp.fc2.weight
        , %para231 : Ref[Tensor(F32)][64]    # adam_m.backbone.blocks1.0.mlp.fc2.bias
        , %para232 : Ref[Tensor(F32)][64]    # adam_m.backbone.blocks1.1.norm1.gamma
        , %para233 : Ref[Tensor(F32)][64]    # adam_m.backbone.blocks1.1.norm1.beta
        , %para234 : Ref[Tensor(F32)][192, 64]    # adam_m.backbone.blocks1.1.mixer.qkv.weight
        , %para235 : Ref[Tensor(F32)][192]    # adam_m.backbone.blocks1.1.mixer.qkv.bias
        , %para236 : Ref[Tensor(F32)][64, 64]    # adam_m.backbone.blocks1.1.mixer.proj.weight
        , %para237 : Ref[Tensor(F32)][64]    # adam_m.backbone.blocks1.1.mixer.proj.bias
        , %para238 : Ref[Tensor(F32)][64]    # adam_m.backbone.blocks1.1.norm2.gamma
        , %para239 : Ref[Tensor(F32)][64]    # adam_m.backbone.blocks1.1.norm2.beta
        , %para240 : Ref[Tensor(F32)][256, 64]    # adam_m.backbone.blocks1.1.mlp.fc1.weight
        , %para241 : Ref[Tensor(F32)][256]    # adam_m.backbone.blocks1.1.mlp.fc1.bias
        , %para242 : Ref[Tensor(F32)][64, 256]    # adam_m.backbone.blocks1.1.mlp.fc2.weight
        , %para243 : Ref[Tensor(F32)][64]    # adam_m.backbone.blocks1.1.mlp.fc2.bias
        , %para244 : Ref[Tensor(F32)][64]    # adam_m.backbone.blocks1.2.norm1.gamma
        , %para245 : Ref[Tensor(F32)][64]    # adam_m.backbone.blocks1.2.norm1.beta
        , %para246 : Ref[Tensor(F32)][192, 64]    # adam_m.backbone.blocks1.2.mixer.qkv.weight
        , %para247 : Ref[Tensor(F32)][192]    # adam_m.backbone.blocks1.2.mixer.qkv.bias
        , %para248 : Ref[Tensor(F32)][64, 64]    # adam_m.backbone.blocks1.2.mixer.proj.weight
        , %para249 : Ref[Tensor(F32)][64]    # adam_m.backbone.blocks1.2.mixer.proj.bias
        , %para250 : Ref[Tensor(F32)][64]    # adam_m.backbone.blocks1.2.norm2.gamma
        , %para251 : Ref[Tensor(F32)][64]    # adam_m.backbone.blocks1.2.norm2.beta
        , %para252 : Ref[Tensor(F32)][256, 64]    # adam_m.backbone.blocks1.2.mlp.fc1.weight
        , %para253 : Ref[Tensor(F32)][256]    # adam_m.backbone.blocks1.2.mlp.fc1.bias
        , %para254 : Ref[Tensor(F32)][64, 256]    # adam_m.backbone.blocks1.2.mlp.fc2.weight
        , %para255 : Ref[Tensor(F32)][64]    # adam_m.backbone.blocks1.2.mlp.fc2.bias
        , %para256 : Ref[Tensor(F32)][128, 64, 3, 3]    # adam_m.backbone.sub_sample1.conv.weight
        , %para257 : Ref[Tensor(F32)][128]    # adam_m.backbone.sub_sample1.norm.gamma
        , %para258 : Ref[Tensor(F32)][128]    # adam_m.backbone.sub_sample1.norm.beta
        , %para259 : Ref[Tensor(F32)][128]    # adam_m.backbone.blocks2.0.norm1.gamma
        , %para260 : Ref[Tensor(F32)][128]    # adam_m.backbone.blocks2.0.norm1.beta
        , %para261 : Ref[Tensor(F32)][384, 128]    # adam_m.backbone.blocks2.0.mixer.qkv.weight
        , %para262 : Ref[Tensor(F32)][384]    # adam_m.backbone.blocks2.0.mixer.qkv.bias
        , %para263 : Ref[Tensor(F32)][128, 128]    # adam_m.backbone.blocks2.0.mixer.proj.weight
        , %para264 : Ref[Tensor(F32)][128]    # adam_m.backbone.blocks2.0.mixer.proj.bias
        , %para265 : Ref[Tensor(F32)][128]    # adam_m.backbone.blocks2.0.norm2.gamma
        , %para266 : Ref[Tensor(F32)][128]    # adam_m.backbone.blocks2.0.norm2.beta
        , %para267 : Ref[Tensor(F32)][512, 128]    # adam_m.backbone.blocks2.0.mlp.fc1.weight
        , %para268 : Ref[Tensor(F32)][512]    # adam_m.backbone.blocks2.0.mlp.fc1.bias
        , %para269 : Ref[Tensor(F32)][128, 512]    # adam_m.backbone.blocks2.0.mlp.fc2.weight
        , %para270 : Ref[Tensor(F32)][128]    # adam_m.backbone.blocks2.0.mlp.fc2.bias
        , %para271 : Ref[Tensor(F32)][128]    # adam_m.backbone.blocks2.1.norm1.gamma
        , %para272 : Ref[Tensor(F32)][128]    # adam_m.backbone.blocks2.1.norm1.beta
        , %para273 : Ref[Tensor(F32)][384, 128]    # adam_m.backbone.blocks2.1.mixer.qkv.weight
        , %para274 : Ref[Tensor(F32)][384]    # adam_m.backbone.blocks2.1.mixer.qkv.bias
        , %para275 : Ref[Tensor(F32)][128, 128]    # adam_m.backbone.blocks2.1.mixer.proj.weight
        , %para276 : Ref[Tensor(F32)][128]    # adam_m.backbone.blocks2.1.mixer.proj.bias
        , %para277 : Ref[Tensor(F32)][128]    # adam_m.backbone.blocks2.1.norm2.gamma
        , %para278 : Ref[Tensor(F32)][128]    # adam_m.backbone.blocks2.1.norm2.beta
        , %para279 : Ref[Tensor(F32)][512, 128]    # adam_m.backbone.blocks2.1.mlp.fc1.weight
        , %para280 : Ref[Tensor(F32)][512]    # adam_m.backbone.blocks2.1.mlp.fc1.bias
        , %para281 : Ref[Tensor(F32)][128, 512]    # adam_m.backbone.blocks2.1.mlp.fc2.weight
        , %para282 : Ref[Tensor(F32)][128]    # adam_m.backbone.blocks2.1.mlp.fc2.bias
        , %para283 : Ref[Tensor(F32)][128]    # adam_m.backbone.blocks2.2.norm1.gamma
        , %para284 : Ref[Tensor(F32)][128]    # adam_m.backbone.blocks2.2.norm1.beta
        , %para285 : Ref[Tensor(F32)][384, 128]    # adam_m.backbone.blocks2.2.mixer.qkv.weight
        , %para286 : Ref[Tensor(F32)][384]    # adam_m.backbone.blocks2.2.mixer.qkv.bias
        , %para287 : Ref[Tensor(F32)][128, 128]    # adam_m.backbone.blocks2.2.mixer.proj.weight
        , %para288 : Ref[Tensor(F32)][128]    # adam_m.backbone.blocks2.2.mixer.proj.bias
        , %para289 : Ref[Tensor(F32)][128]    # adam_m.backbone.blocks2.2.norm2.gamma
        , %para290 : Ref[Tensor(F32)][128]    # adam_m.backbone.blocks2.2.norm2.beta
        , %para291 : Ref[Tensor(F32)][512, 128]    # adam_m.backbone.blocks2.2.mlp.fc1.weight
        , %para292 : Ref[Tensor(F32)][512]    # adam_m.backbone.blocks2.2.mlp.fc1.bias
        , %para293 : Ref[Tensor(F32)][128, 512]    # adam_m.backbone.blocks2.2.mlp.fc2.weight
        , %para294 : Ref[Tensor(F32)][128]    # adam_m.backbone.blocks2.2.mlp.fc2.bias
        , %para295 : Ref[Tensor(F32)][128]    # adam_m.backbone.blocks2.3.norm1.gamma
        , %para296 : Ref[Tensor(F32)][128]    # adam_m.backbone.blocks2.3.norm1.beta
        , %para297 : Ref[Tensor(F32)][384, 128]    # adam_m.backbone.blocks2.3.mixer.qkv.weight
        , %para298 : Ref[Tensor(F32)][384]    # adam_m.backbone.blocks2.3.mixer.qkv.bias
        , %para299 : Ref[Tensor(F32)][128, 128]    # adam_m.backbone.blocks2.3.mixer.proj.weight
        , %para300 : Ref[Tensor(F32)][128]    # adam_m.backbone.blocks2.3.mixer.proj.bias
        , %para301 : Ref[Tensor(F32)][128]    # adam_m.backbone.blocks2.3.norm2.gamma
        , %para302 : Ref[Tensor(F32)][128]    # adam_m.backbone.blocks2.3.norm2.beta
        , %para303 : Ref[Tensor(F32)][512, 128]    # adam_m.backbone.blocks2.3.mlp.fc1.weight
        , %para304 : Ref[Tensor(F32)][512]    # adam_m.backbone.blocks2.3.mlp.fc1.bias
        , %para305 : Ref[Tensor(F32)][128, 512]    # adam_m.backbone.blocks2.3.mlp.fc2.weight
        , %para306 : Ref[Tensor(F32)][128]    # adam_m.backbone.blocks2.3.mlp.fc2.bias
        , %para307 : Ref[Tensor(F32)][128]    # adam_m.backbone.blocks2.4.norm1.gamma
        , %para308 : Ref[Tensor(F32)][128]    # adam_m.backbone.blocks2.4.norm1.beta
        , %para309 : Ref[Tensor(F32)][384, 128]    # adam_m.backbone.blocks2.4.mixer.qkv.weight
        , %para310 : Ref[Tensor(F32)][384]    # adam_m.backbone.blocks2.4.mixer.qkv.bias
        , %para311 : Ref[Tensor(F32)][128, 128]    # adam_m.backbone.blocks2.4.mixer.proj.weight
        , %para312 : Ref[Tensor(F32)][128]    # adam_m.backbone.blocks2.4.mixer.proj.bias
        , %para313 : Ref[Tensor(F32)][128]    # adam_m.backbone.blocks2.4.norm2.gamma
        , %para314 : Ref[Tensor(F32)][128]    # adam_m.backbone.blocks2.4.norm2.beta
        , %para315 : Ref[Tensor(F32)][512, 128]    # adam_m.backbone.blocks2.4.mlp.fc1.weight
        , %para316 : Ref[Tensor(F32)][512]    # adam_m.backbone.blocks2.4.mlp.fc1.bias
        , %para317 : Ref[Tensor(F32)][128, 512]    # adam_m.backbone.blocks2.4.mlp.fc2.weight
        , %para318 : Ref[Tensor(F32)][128]    # adam_m.backbone.blocks2.4.mlp.fc2.bias
        , %para319 : Ref[Tensor(F32)][128]    # adam_m.backbone.blocks2.5.norm1.gamma
        , %para320 : Ref[Tensor(F32)][128]    # adam_m.backbone.blocks2.5.norm1.beta
        , %para321 : Ref[Tensor(F32)][384, 128]    # adam_m.backbone.blocks2.5.mixer.qkv.weight
        , %para322 : Ref[Tensor(F32)][384]    # adam_m.backbone.blocks2.5.mixer.qkv.bias
        , %para323 : Ref[Tensor(F32)][128, 128]    # adam_m.backbone.blocks2.5.mixer.proj.weight
        , %para324 : Ref[Tensor(F32)][128]    # adam_m.backbone.blocks2.5.mixer.proj.bias
        , %para325 : Ref[Tensor(F32)][128]    # adam_m.backbone.blocks2.5.norm2.gamma
        , %para326 : Ref[Tensor(F32)][128]    # adam_m.backbone.blocks2.5.norm2.beta
        , %para327 : Ref[Tensor(F32)][512, 128]    # adam_m.backbone.blocks2.5.mlp.fc1.weight
        , %para328 : Ref[Tensor(F32)][512]    # adam_m.backbone.blocks2.5.mlp.fc1.bias
        , %para329 : Ref[Tensor(F32)][128, 512]    # adam_m.backbone.blocks2.5.mlp.fc2.weight
        , %para330 : Ref[Tensor(F32)][128]    # adam_m.backbone.blocks2.5.mlp.fc2.bias
        , %para331 : Ref[Tensor(F32)][256, 128, 3, 3]    # adam_m.backbone.sub_sample2.conv.weight
        , %para332 : Ref[Tensor(F32)][256]    # adam_m.backbone.sub_sample2.norm.gamma
        , %para333 : Ref[Tensor(F32)][256]    # adam_m.backbone.sub_sample2.norm.beta
        , %para334 : Ref[Tensor(F32)][256]    # adam_m.backbone.blocks3.0.norm1.gamma
        , %para335 : Ref[Tensor(F32)][256]    # adam_m.backbone.blocks3.0.norm1.beta
        , %para336 : Ref[Tensor(F32)][768, 256]    # adam_m.backbone.blocks3.0.mixer.qkv.weight
        , %para337 : Ref[Tensor(F32)][768]    # adam_m.backbone.blocks3.0.mixer.qkv.bias
        , %para338 : Ref[Tensor(F32)][256, 256]    # adam_m.backbone.blocks3.0.mixer.proj.weight
        , %para339 : Ref[Tensor(F32)][256]    # adam_m.backbone.blocks3.0.mixer.proj.bias
        , %para340 : Ref[Tensor(F32)][256]    # adam_m.backbone.blocks3.0.norm2.gamma
        , %para341 : Ref[Tensor(F32)][256]    # adam_m.backbone.blocks3.0.norm2.beta
        , %para342 : Ref[Tensor(F32)][1024, 256]    # adam_m.backbone.blocks3.0.mlp.fc1.weight
        , %para343 : Ref[Tensor(F32)][1024]    # adam_m.backbone.blocks3.0.mlp.fc1.bias
        , %para344 : Ref[Tensor(F32)][256, 1024]    # adam_m.backbone.blocks3.0.mlp.fc2.weight
        , %para345 : Ref[Tensor(F32)][256]    # adam_m.backbone.blocks3.0.mlp.fc2.bias
        , %para346 : Ref[Tensor(F32)][256]    # adam_m.backbone.blocks3.1.norm1.gamma
        , %para347 : Ref[Tensor(F32)][256]    # adam_m.backbone.blocks3.1.norm1.beta
        , %para348 : Ref[Tensor(F32)][768, 256]    # adam_m.backbone.blocks3.1.mixer.qkv.weight
        , %para349 : Ref[Tensor(F32)][768]    # adam_m.backbone.blocks3.1.mixer.qkv.bias
        , %para350 : Ref[Tensor(F32)][256, 256]    # adam_m.backbone.blocks3.1.mixer.proj.weight
        , %para351 : Ref[Tensor(F32)][256]    # adam_m.backbone.blocks3.1.mixer.proj.bias
        , %para352 : Ref[Tensor(F32)][256]    # adam_m.backbone.blocks3.1.norm2.gamma
        , %para353 : Ref[Tensor(F32)][256]    # adam_m.backbone.blocks3.1.norm2.beta
        , %para354 : Ref[Tensor(F32)][1024, 256]    # adam_m.backbone.blocks3.1.mlp.fc1.weight
        , %para355 : Ref[Tensor(F32)][1024]    # adam_m.backbone.blocks3.1.mlp.fc1.bias
        , %para356 : Ref[Tensor(F32)][256, 1024]    # adam_m.backbone.blocks3.1.mlp.fc2.weight
        , %para357 : Ref[Tensor(F32)][256]    # adam_m.backbone.blocks3.1.mlp.fc2.bias
        , %para358 : Ref[Tensor(F32)][256]    # adam_m.backbone.blocks3.2.norm1.gamma
        , %para359 : Ref[Tensor(F32)][256]    # adam_m.backbone.blocks3.2.norm1.beta
        , %para360 : Ref[Tensor(F32)][768, 256]    # adam_m.backbone.blocks3.2.mixer.qkv.weight
        , %para361 : Ref[Tensor(F32)][768]    # adam_m.backbone.blocks3.2.mixer.qkv.bias
        , %para362 : Ref[Tensor(F32)][256, 256]    # adam_m.backbone.blocks3.2.mixer.proj.weight
        , %para363 : Ref[Tensor(F32)][256]    # adam_m.backbone.blocks3.2.mixer.proj.bias
        , %para364 : Ref[Tensor(F32)][256]    # adam_m.backbone.blocks3.2.norm2.gamma
        , %para365 : Ref[Tensor(F32)][256]    # adam_m.backbone.blocks3.2.norm2.beta
        , %para366 : Ref[Tensor(F32)][1024, 256]    # adam_m.backbone.blocks3.2.mlp.fc1.weight
        , %para367 : Ref[Tensor(F32)][1024]    # adam_m.backbone.blocks3.2.mlp.fc1.bias
        , %para368 : Ref[Tensor(F32)][256, 1024]    # adam_m.backbone.blocks3.2.mlp.fc2.weight
        , %para369 : Ref[Tensor(F32)][256]    # adam_m.backbone.blocks3.2.mlp.fc2.bias
        , %para370 : Ref[Tensor(F32)][192, 256, 1, 1]    # adam_m.backbone.last_conv.weight
        , %para371 : Ref[Tensor(F32)][256]    # adam_m.backbone.norm.gamma
        , %para372 : Ref[Tensor(F32)][256]    # adam_m.backbone.norm.beta
        , %para373 : Ref[Tensor(F32)][37, 192]    # adam_m.head.fc.weight
        , %para374 : Ref[Tensor(F32)][37]    # adam_m.head.fc.bias
        , %para375 : Ref[Tensor(F32)][32, 3, 3, 3]    # adam_v.transform.stn_head.stn_convnet.0.0.weight
        , %para376 : Ref[Tensor(F32)][32]    # adam_v.transform.stn_head.stn_convnet.0.1.gamma
        , %para377 : Ref[Tensor(F32)][32]    # adam_v.transform.stn_head.stn_convnet.0.1.beta
        , %para378 : Ref[Tensor(F32)][64, 32, 3, 3]    # adam_v.transform.stn_head.stn_convnet.2.0.weight
        , %para379 : Ref[Tensor(F32)][64]    # adam_v.transform.stn_head.stn_convnet.2.1.gamma
        , %para380 : Ref[Tensor(F32)][64]    # adam_v.transform.stn_head.stn_convnet.2.1.beta
        , %para381 : Ref[Tensor(F32)][128, 64, 3, 3]    # adam_v.transform.stn_head.stn_convnet.4.0.weight
        , %para382 : Ref[Tensor(F32)][128]    # adam_v.transform.stn_head.stn_convnet.4.1.gamma
        , %para383 : Ref[Tensor(F32)][128]    # adam_v.transform.stn_head.stn_convnet.4.1.beta
        , %para384 : Ref[Tensor(F32)][256, 128, 3, 3]    # adam_v.transform.stn_head.stn_convnet.6.0.weight
        , %para385 : Ref[Tensor(F32)][256]    # adam_v.transform.stn_head.stn_convnet.6.1.gamma
        , %para386 : Ref[Tensor(F32)][256]    # adam_v.transform.stn_head.stn_convnet.6.1.beta
        , %para387 : Ref[Tensor(F32)][256, 256, 3, 3]    # adam_v.transform.stn_head.stn_convnet.8.0.weight
        , %para388 : Ref[Tensor(F32)][256]    # adam_v.transform.stn_head.stn_convnet.8.1.gamma
        , %para389 : Ref[Tensor(F32)][256]    # adam_v.transform.stn_head.stn_convnet.8.1.beta
        , %para390 : Ref[Tensor(F32)][256, 256, 3, 3]    # adam_v.transform.stn_head.stn_convnet.10.0.weight
        , %para391 : Ref[Tensor(F32)][256]    # adam_v.transform.stn_head.stn_convnet.10.1.gamma
        , %para392 : Ref[Tensor(F32)][256]    # adam_v.transform.stn_head.stn_convnet.10.1.beta
        , %para393 : Ref[Tensor(F32)][512, 512]    # adam_v.transform.stn_head.stn_fc1.0.weight
        , %para394 : Ref[Tensor(F32)][512]    # adam_v.transform.stn_head.stn_fc1.0.bias
        , %para395 : Ref[Tensor(F32)][512]    # adam_v.transform.stn_head.stn_fc1.1.gamma
        , %para396 : Ref[Tensor(F32)][512]    # adam_v.transform.stn_head.stn_fc1.1.beta
        , %para397 : Ref[Tensor(F32)][40, 512]    # adam_v.transform.stn_head.stn_fc2.weight
        , %para398 : Ref[Tensor(F32)][40]    # adam_v.transform.stn_head.stn_fc2.bias
        , %para399 : Ref[Tensor(F32)][1, 200, 64]    # adam_v.backbone.pos_embed
        , %para400 : Ref[Tensor(F32)][32, 3, 3, 3]    # adam_v.backbone.patch_embed.proj.0.conv.weight
        , %para401 : Ref[Tensor(F32)][32]    # adam_v.backbone.patch_embed.proj.0.norm.gamma
        , %para402 : Ref[Tensor(F32)][32]    # adam_v.backbone.patch_embed.proj.0.norm.beta
        , %para403 : Ref[Tensor(F32)][64, 32, 3, 3]    # adam_v.backbone.patch_embed.proj.1.conv.weight
        , %para404 : Ref[Tensor(F32)][64]    # adam_v.backbone.patch_embed.proj.1.norm.gamma
        , %para405 : Ref[Tensor(F32)][64]    # adam_v.backbone.patch_embed.proj.1.norm.beta
        , %para406 : Ref[Tensor(F32)][64]    # adam_v.backbone.blocks1.0.norm1.gamma
        , %para407 : Ref[Tensor(F32)][64]    # adam_v.backbone.blocks1.0.norm1.beta
        , %para408 : Ref[Tensor(F32)][192, 64]    # adam_v.backbone.blocks1.0.mixer.qkv.weight
        , %para409 : Ref[Tensor(F32)][192]    # adam_v.backbone.blocks1.0.mixer.qkv.bias
        , %para410 : Ref[Tensor(F32)][64, 64]    # adam_v.backbone.blocks1.0.mixer.proj.weight
        , %para411 : Ref[Tensor(F32)][64]    # adam_v.backbone.blocks1.0.mixer.proj.bias
        , %para412 : Ref[Tensor(F32)][64]    # adam_v.backbone.blocks1.0.norm2.gamma
        , %para413 : Ref[Tensor(F32)][64]    # adam_v.backbone.blocks1.0.norm2.beta
        , %para414 : Ref[Tensor(F32)][256, 64]    # adam_v.backbone.blocks1.0.mlp.fc1.weight
        , %para415 : Ref[Tensor(F32)][256]    # adam_v.backbone.blocks1.0.mlp.fc1.bias
        , %para416 : Ref[Tensor(F32)][64, 256]    # adam_v.backbone.blocks1.0.mlp.fc2.weight
        , %para417 : Ref[Tensor(F32)][64]    # adam_v.backbone.blocks1.0.mlp.fc2.bias
        , %para418 : Ref[Tensor(F32)][64]    # adam_v.backbone.blocks1.1.norm1.gamma
        , %para419 : Ref[Tensor(F32)][64]    # adam_v.backbone.blocks1.1.norm1.beta
        , %para420 : Ref[Tensor(F32)][192, 64]    # adam_v.backbone.blocks1.1.mixer.qkv.weight
        , %para421 : Ref[Tensor(F32)][192]    # adam_v.backbone.blocks1.1.mixer.qkv.bias
        , %para422 : Ref[Tensor(F32)][64, 64]    # adam_v.backbone.blocks1.1.mixer.proj.weight
        , %para423 : Ref[Tensor(F32)][64]    # adam_v.backbone.blocks1.1.mixer.proj.bias
        , %para424 : Ref[Tensor(F32)][64]    # adam_v.backbone.blocks1.1.norm2.gamma
        , %para425 : Ref[Tensor(F32)][64]    # adam_v.backbone.blocks1.1.norm2.beta
        , %para426 : Ref[Tensor(F32)][256, 64]    # adam_v.backbone.blocks1.1.mlp.fc1.weight
        , %para427 : Ref[Tensor(F32)][256]    # adam_v.backbone.blocks1.1.mlp.fc1.bias
        , %para428 : Ref[Tensor(F32)][64, 256]    # adam_v.backbone.blocks1.1.mlp.fc2.weight
        , %para429 : Ref[Tensor(F32)][64]    # adam_v.backbone.blocks1.1.mlp.fc2.bias
        , %para430 : Ref[Tensor(F32)][64]    # adam_v.backbone.blocks1.2.norm1.gamma
        , %para431 : Ref[Tensor(F32)][64]    # adam_v.backbone.blocks1.2.norm1.beta
        , %para432 : Ref[Tensor(F32)][192, 64]    # adam_v.backbone.blocks1.2.mixer.qkv.weight
        , %para433 : Ref[Tensor(F32)][192]    # adam_v.backbone.blocks1.2.mixer.qkv.bias
        , %para434 : Ref[Tensor(F32)][64, 64]    # adam_v.backbone.blocks1.2.mixer.proj.weight
        , %para435 : Ref[Tensor(F32)][64]    # adam_v.backbone.blocks1.2.mixer.proj.bias
        , %para436 : Ref[Tensor(F32)][64]    # adam_v.backbone.blocks1.2.norm2.gamma
        , %para437 : Ref[Tensor(F32)][64]    # adam_v.backbone.blocks1.2.norm2.beta
        , %para438 : Ref[Tensor(F32)][256, 64]    # adam_v.backbone.blocks1.2.mlp.fc1.weight
        , %para439 : Ref[Tensor(F32)][256]    # adam_v.backbone.blocks1.2.mlp.fc1.bias
        , %para440 : Ref[Tensor(F32)][64, 256]    # adam_v.backbone.blocks1.2.mlp.fc2.weight
        , %para441 : Ref[Tensor(F32)][64]    # adam_v.backbone.blocks1.2.mlp.fc2.bias
        , %para442 : Ref[Tensor(F32)][128, 64, 3, 3]    # adam_v.backbone.sub_sample1.conv.weight
        , %para443 : Ref[Tensor(F32)][128]    # adam_v.backbone.sub_sample1.norm.gamma
        , %para444 : Ref[Tensor(F32)][128]    # adam_v.backbone.sub_sample1.norm.beta
        , %para445 : Ref[Tensor(F32)][128]    # adam_v.backbone.blocks2.0.norm1.gamma
        , %para446 : Ref[Tensor(F32)][128]    # adam_v.backbone.blocks2.0.norm1.beta
        , %para447 : Ref[Tensor(F32)][384, 128]    # adam_v.backbone.blocks2.0.mixer.qkv.weight
        , %para448 : Ref[Tensor(F32)][384]    # adam_v.backbone.blocks2.0.mixer.qkv.bias
        , %para449 : Ref[Tensor(F32)][128, 128]    # adam_v.backbone.blocks2.0.mixer.proj.weight
        , %para450 : Ref[Tensor(F32)][128]    # adam_v.backbone.blocks2.0.mixer.proj.bias
        , %para451 : Ref[Tensor(F32)][128]    # adam_v.backbone.blocks2.0.norm2.gamma
        , %para452 : Ref[Tensor(F32)][128]    # adam_v.backbone.blocks2.0.norm2.beta
        , %para453 : Ref[Tensor(F32)][512, 128]    # adam_v.backbone.blocks2.0.mlp.fc1.weight
        , %para454 : Ref[Tensor(F32)][512]    # adam_v.backbone.blocks2.0.mlp.fc1.bias
        , %para455 : Ref[Tensor(F32)][128, 512]    # adam_v.backbone.blocks2.0.mlp.fc2.weight
        , %para456 : Ref[Tensor(F32)][128]    # adam_v.backbone.blocks2.0.mlp.fc2.bias
        , %para457 : Ref[Tensor(F32)][128]    # adam_v.backbone.blocks2.1.norm1.gamma
        , %para458 : Ref[Tensor(F32)][128]    # adam_v.backbone.blocks2.1.norm1.beta
        , %para459 : Ref[Tensor(F32)][384, 128]    # adam_v.backbone.blocks2.1.mixer.qkv.weight
        , %para460 : Ref[Tensor(F32)][384]    # adam_v.backbone.blocks2.1.mixer.qkv.bias
        , %para461 : Ref[Tensor(F32)][128, 128]    # adam_v.backbone.blocks2.1.mixer.proj.weight
        , %para462 : Ref[Tensor(F32)][128]    # adam_v.backbone.blocks2.1.mixer.proj.bias
        , %para463 : Ref[Tensor(F32)][128]    # adam_v.backbone.blocks2.1.norm2.gamma
        , %para464 : Ref[Tensor(F32)][128]    # adam_v.backbone.blocks2.1.norm2.beta
        , %para465 : Ref[Tensor(F32)][512, 128]    # adam_v.backbone.blocks2.1.mlp.fc1.weight
        , %para466 : Ref[Tensor(F32)][512]    # adam_v.backbone.blocks2.1.mlp.fc1.bias
        , %para467 : Ref[Tensor(F32)][128, 512]    # adam_v.backbone.blocks2.1.mlp.fc2.weight
        , %para468 : Ref[Tensor(F32)][128]    # adam_v.backbone.blocks2.1.mlp.fc2.bias
        , %para469 : Ref[Tensor(F32)][128]    # adam_v.backbone.blocks2.2.norm1.gamma
        , %para470 : Ref[Tensor(F32)][128]    # adam_v.backbone.blocks2.2.norm1.beta
        , %para471 : Ref[Tensor(F32)][384, 128]    # adam_v.backbone.blocks2.2.mixer.qkv.weight
        , %para472 : Ref[Tensor(F32)][384]    # adam_v.backbone.blocks2.2.mixer.qkv.bias
        , %para473 : Ref[Tensor(F32)][128, 128]    # adam_v.backbone.blocks2.2.mixer.proj.weight
        , %para474 : Ref[Tensor(F32)][128]    # adam_v.backbone.blocks2.2.mixer.proj.bias
        , %para475 : Ref[Tensor(F32)][128]    # adam_v.backbone.blocks2.2.norm2.gamma
        , %para476 : Ref[Tensor(F32)][128]    # adam_v.backbone.blocks2.2.norm2.beta
        , %para477 : Ref[Tensor(F32)][512, 128]    # adam_v.backbone.blocks2.2.mlp.fc1.weight
        , %para478 : Ref[Tensor(F32)][512]    # adam_v.backbone.blocks2.2.mlp.fc1.bias
        , %para479 : Ref[Tensor(F32)][128, 512]    # adam_v.backbone.blocks2.2.mlp.fc2.weight
        , %para480 : Ref[Tensor(F32)][128]    # adam_v.backbone.blocks2.2.mlp.fc2.bias
        , %para481 : Ref[Tensor(F32)][128]    # adam_v.backbone.blocks2.3.norm1.gamma
        , %para482 : Ref[Tensor(F32)][128]    # adam_v.backbone.blocks2.3.norm1.beta
        , %para483 : Ref[Tensor(F32)][384, 128]    # adam_v.backbone.blocks2.3.mixer.qkv.weight
        , %para484 : Ref[Tensor(F32)][384]    # adam_v.backbone.blocks2.3.mixer.qkv.bias
        , %para485 : Ref[Tensor(F32)][128, 128]    # adam_v.backbone.blocks2.3.mixer.proj.weight
        , %para486 : Ref[Tensor(F32)][128]    # adam_v.backbone.blocks2.3.mixer.proj.bias
        , %para487 : Ref[Tensor(F32)][128]    # adam_v.backbone.blocks2.3.norm2.gamma
        , %para488 : Ref[Tensor(F32)][128]    # adam_v.backbone.blocks2.3.norm2.beta
        , %para489 : Ref[Tensor(F32)][512, 128]    # adam_v.backbone.blocks2.3.mlp.fc1.weight
        , %para490 : Ref[Tensor(F32)][512]    # adam_v.backbone.blocks2.3.mlp.fc1.bias
        , %para491 : Ref[Tensor(F32)][128, 512]    # adam_v.backbone.blocks2.3.mlp.fc2.weight
        , %para492 : Ref[Tensor(F32)][128]    # adam_v.backbone.blocks2.3.mlp.fc2.bias
        , %para493 : Ref[Tensor(F32)][128]    # adam_v.backbone.blocks2.4.norm1.gamma
        , %para494 : Ref[Tensor(F32)][128]    # adam_v.backbone.blocks2.4.norm1.beta
        , %para495 : Ref[Tensor(F32)][384, 128]    # adam_v.backbone.blocks2.4.mixer.qkv.weight
        , %para496 : Ref[Tensor(F32)][384]    # adam_v.backbone.blocks2.4.mixer.qkv.bias
        , %para497 : Ref[Tensor(F32)][128, 128]    # adam_v.backbone.blocks2.4.mixer.proj.weight
        , %para498 : Ref[Tensor(F32)][128]    # adam_v.backbone.blocks2.4.mixer.proj.bias
        , %para499 : Ref[Tensor(F32)][128]    # adam_v.backbone.blocks2.4.norm2.gamma
        , %para500 : Ref[Tensor(F32)][128]    # adam_v.backbone.blocks2.4.norm2.beta
        , %para501 : Ref[Tensor(F32)][512, 128]    # adam_v.backbone.blocks2.4.mlp.fc1.weight
        , %para502 : Ref[Tensor(F32)][512]    # adam_v.backbone.blocks2.4.mlp.fc1.bias
        , %para503 : Ref[Tensor(F32)][128, 512]    # adam_v.backbone.blocks2.4.mlp.fc2.weight
        , %para504 : Ref[Tensor(F32)][128]    # adam_v.backbone.blocks2.4.mlp.fc2.bias
        , %para505 : Ref[Tensor(F32)][128]    # adam_v.backbone.blocks2.5.norm1.gamma
        , %para506 : Ref[Tensor(F32)][128]    # adam_v.backbone.blocks2.5.norm1.beta
        , %para507 : Ref[Tensor(F32)][384, 128]    # adam_v.backbone.blocks2.5.mixer.qkv.weight
        , %para508 : Ref[Tensor(F32)][384]    # adam_v.backbone.blocks2.5.mixer.qkv.bias
        , %para509 : Ref[Tensor(F32)][128, 128]    # adam_v.backbone.blocks2.5.mixer.proj.weight
        , %para510 : Ref[Tensor(F32)][128]    # adam_v.backbone.blocks2.5.mixer.proj.bias
        , %para511 : Ref[Tensor(F32)][128]    # adam_v.backbone.blocks2.5.norm2.gamma
        , %para512 : Ref[Tensor(F32)][128]    # adam_v.backbone.blocks2.5.norm2.beta
        , %para513 : Ref[Tensor(F32)][512, 128]    # adam_v.backbone.blocks2.5.mlp.fc1.weight
        , %para514 : Ref[Tensor(F32)][512]    # adam_v.backbone.blocks2.5.mlp.fc1.bias
        , %para515 : Ref[Tensor(F32)][128, 512]    # adam_v.backbone.blocks2.5.mlp.fc2.weight
        , %para516 : Ref[Tensor(F32)][128]    # adam_v.backbone.blocks2.5.mlp.fc2.bias
        , %para517 : Ref[Tensor(F32)][256, 128, 3, 3]    # adam_v.backbone.sub_sample2.conv.weight
        , %para518 : Ref[Tensor(F32)][256]    # adam_v.backbone.sub_sample2.norm.gamma
        , %para519 : Ref[Tensor(F32)][256]    # adam_v.backbone.sub_sample2.norm.beta
        , %para520 : Ref[Tensor(F32)][256]    # adam_v.backbone.blocks3.0.norm1.gamma
        , %para521 : Ref[Tensor(F32)][256]    # adam_v.backbone.blocks3.0.norm1.beta
        , %para522 : Ref[Tensor(F32)][768, 256]    # adam_v.backbone.blocks3.0.mixer.qkv.weight
        , %para523 : Ref[Tensor(F32)][768]    # adam_v.backbone.blocks3.0.mixer.qkv.bias
        , %para524 : Ref[Tensor(F32)][256, 256]    # adam_v.backbone.blocks3.0.mixer.proj.weight
        , %para525 : Ref[Tensor(F32)][256]    # adam_v.backbone.blocks3.0.mixer.proj.bias
        , %para526 : Ref[Tensor(F32)][256]    # adam_v.backbone.blocks3.0.norm2.gamma
        , %para527 : Ref[Tensor(F32)][256]    # adam_v.backbone.blocks3.0.norm2.beta
        , %para528 : Ref[Tensor(F32)][1024, 256]    # adam_v.backbone.blocks3.0.mlp.fc1.weight
        , %para529 : Ref[Tensor(F32)][1024]    # adam_v.backbone.blocks3.0.mlp.fc1.bias
        , %para530 : Ref[Tensor(F32)][256, 1024]    # adam_v.backbone.blocks3.0.mlp.fc2.weight
        , %para531 : Ref[Tensor(F32)][256]    # adam_v.backbone.blocks3.0.mlp.fc2.bias
        , %para532 : Ref[Tensor(F32)][256]    # adam_v.backbone.blocks3.1.norm1.gamma
        , %para533 : Ref[Tensor(F32)][256]    # adam_v.backbone.blocks3.1.norm1.beta
        , %para534 : Ref[Tensor(F32)][768, 256]    # adam_v.backbone.blocks3.1.mixer.qkv.weight
        , %para535 : Ref[Tensor(F32)][768]    # adam_v.backbone.blocks3.1.mixer.qkv.bias
        , %para536 : Ref[Tensor(F32)][256, 256]    # adam_v.backbone.blocks3.1.mixer.proj.weight
        , %para537 : Ref[Tensor(F32)][256]    # adam_v.backbone.blocks3.1.mixer.proj.bias
        , %para538 : Ref[Tensor(F32)][256]    # adam_v.backbone.blocks3.1.norm2.gamma
        , %para539 : Ref[Tensor(F32)][256]    # adam_v.backbone.blocks3.1.norm2.beta
        , %para540 : Ref[Tensor(F32)][1024, 256]    # adam_v.backbone.blocks3.1.mlp.fc1.weight
        , %para541 : Ref[Tensor(F32)][1024]    # adam_v.backbone.blocks3.1.mlp.fc1.bias
        , %para542 : Ref[Tensor(F32)][256, 1024]    # adam_v.backbone.blocks3.1.mlp.fc2.weight
        , %para543 : Ref[Tensor(F32)][256]    # adam_v.backbone.blocks3.1.mlp.fc2.bias
        , %para544 : Ref[Tensor(F32)][256]    # adam_v.backbone.blocks3.2.norm1.gamma
        , %para545 : Ref[Tensor(F32)][256]    # adam_v.backbone.blocks3.2.norm1.beta
        , %para546 : Ref[Tensor(F32)][768, 256]    # adam_v.backbone.blocks3.2.mixer.qkv.weight
        , %para547 : Ref[Tensor(F32)][768]    # adam_v.backbone.blocks3.2.mixer.qkv.bias
        , %para548 : Ref[Tensor(F32)][256, 256]    # adam_v.backbone.blocks3.2.mixer.proj.weight
        , %para549 : Ref[Tensor(F32)][256]    # adam_v.backbone.blocks3.2.mixer.proj.bias
        , %para550 : Ref[Tensor(F32)][256]    # adam_v.backbone.blocks3.2.norm2.gamma
        , %para551 : Ref[Tensor(F32)][256]    # adam_v.backbone.blocks3.2.norm2.beta
        , %para552 : Ref[Tensor(F32)][1024, 256]    # adam_v.backbone.blocks3.2.mlp.fc1.weight
        , %para553 : Ref[Tensor(F32)][1024]    # adam_v.backbone.blocks3.2.mlp.fc1.bias
        , %para554 : Ref[Tensor(F32)][256, 1024]    # adam_v.backbone.blocks3.2.mlp.fc2.weight
        , %para555 : Ref[Tensor(F32)][256]    # adam_v.backbone.blocks3.2.mlp.fc2.bias
        , %para556 : Ref[Tensor(F32)][192, 256, 1, 1]    # adam_v.backbone.last_conv.weight
        , %para557 : Ref[Tensor(F32)][256]    # adam_v.backbone.norm.gamma
        , %para558 : Ref[Tensor(F32)][256]    # adam_v.backbone.norm.beta
        , %para559 : Ref[Tensor(F32)][37, 192]    # adam_v.head.fc.weight
        , %para560 : Ref[Tensor(F32)][37]    # adam_v.head.fc.bias
        , %para561 : Ref[Tensor(F32)][260]    # learning_rate
        , %para562 : Ref[Tensor(I32)][1]    # global_step
        , %para563 : Ref[Tensor(F32)][512]    # transform.stn_head.stn_fc1.1.moving_mean
        , %para564 : Ref[Tensor(F32)][512]    # transform.stn_head.stn_fc1.1.moving_variance
        , %para565 : Ref[Tensor(F32)][32]    # transform.stn_head.stn_convnet.0.1.moving_mean
        , %para566 : Ref[Tensor(F32)][32]    # transform.stn_head.stn_convnet.0.1.moving_variance
        , %para567 : Ref[Tensor(F32)][64]    # transform.stn_head.stn_convnet.2.1.moving_mean
        , %para568 : Ref[Tensor(F32)][64]    # transform.stn_head.stn_convnet.2.1.moving_variance
        , %para569 : Ref[Tensor(F32)][128]    # transform.stn_head.stn_convnet.4.1.moving_mean
        , %para570 : Ref[Tensor(F32)][128]    # transform.stn_head.stn_convnet.4.1.moving_variance
        , %para571 : Ref[Tensor(F32)][256]    # transform.stn_head.stn_convnet.6.1.moving_mean
        , %para572 : Ref[Tensor(F32)][256]    # transform.stn_head.stn_convnet.6.1.moving_variance
        , %para573 : Ref[Tensor(F32)][256]    # transform.stn_head.stn_convnet.8.1.moving_mean
        , %para574 : Ref[Tensor(F32)][256]    # transform.stn_head.stn_convnet.8.1.moving_variance
        , %para575 : Ref[Tensor(F32)][256]    # transform.stn_head.stn_convnet.10.1.moving_mean
        , %para576 : Ref[Tensor(F32)][256]    # transform.stn_head.stn_convnet.10.1.moving_variance
        , %para577 : Ref[Tensor(F32)][32]    # backbone.patch_embed.proj.0.norm.moving_mean
        , %para578 : Ref[Tensor(F32)][32]    # backbone.patch_embed.proj.0.norm.moving_variance
        , %para579 : Ref[Tensor(F32)][64]    # backbone.patch_embed.proj.1.norm.moving_mean
        , %para580 : Ref[Tensor(F32)][64]    # backbone.patch_embed.proj.1.norm.moving_variance
    ) {
    %1 : Tuple[Tensor(F32),Tensor(I64)]TupleShape((64, 3, 64, 256), (64, 25)) = Primitive::MakeTuple{prim_type=1}(%para1, %para2)    #(Tensor(F32)[64, 3, 64, 256], Tensor(I64)[64, 25]) #scope: Default
#[CNode]62

#------------------------> 0
    %2 = UnpackCall::unpack_call(FuncGraph::fg_63, %1)    #(FuncNoShape, Tuple[Tensor(F32),Tensor(I64)]TupleShape((64, 3, 64, 256), (64, 25)))    # fg_63=Default.63 #scope: Default
#[CNode]64
    Primitive::Return{prim_type=1}(%2)    #(Undefined) #scope: Default
      # In file /home/mindspore/anaconda3/envs/ms1.9/lib/python3.7/site-packages/mindspore/nn/wrap/cell_wrapper.py:385/        return loss/#[CNode]65
}
# order:
#   1: @Default_wrapper.29:[CNode]64{[0]: ValueNode<UnpackCall> unpack_call.66, [1]: ValueNode<FuncGraph> Default.63, [2]: [CNode]62}
#   2: @Default_wrapper.29:[CNode]65{[0]: ValueNode<Primitive> Return, [1]: [CNode]64}


# [No.2] UnpackCall.30

funcgraph fg_30(
        %para581 : FuncNoShape    # 31
        , %para582 : Tuple[Tensor(F32),Tensor(I64)]TupleShape((64, 3, 64, 256), (64, 25))    # 32
    ) {
    %1 : Tensor(F32)[64, 3, 64, 256] = Primitive::TupleGetItem{prim_type=1}(%para582, I64(0))    #(Tuple[Tensor(F32),Tensor(I64)]TupleShape((64, 3, 64, 256), (64, 25)), I64NoShape) #scope: Default
#67
    %2 : Tensor(I64)[64, 25] = Primitive::TupleGetItem{prim_type=1}(%para582, I64(1))    #(Tuple[Tensor(F32),Tensor(I64)]TupleShape((64, 3, 64, 256), (64, 25)), I64NoShape) #scope: Default
#68

#------------------------> 1
    %3 = %para581(%1, %2)    #(Tensor(F32)[64, 3, 64, 256], Tensor(I64)[64, 25]) #scope: Default
#69
    Primitive::Return{prim_type=1}(%3)    #(Undefined) #scope: Default
#70
}
# order:
#   1: @UnpackCall.30:69{[0]: 31, [1]: 67, [2]: 68}
#   2: @UnpackCall.30:70{[0]: ValueNode<Primitive> Return, [1]: 69}


# [No.3] Default.33
# In file /home/mindspore/anaconda3/envs/ms1.9/lib/python3.7/site-packages/mindspore/nn/wrap/cell_wrapper.py:379/    def construct(self, *inputs):/
funcgraph fg_33[fg_29](
        %para583 : Tensor(F32)[64, 3, 64, 256]    # inputs0
        , %para584 : Tensor(I64)[64, 25]    # inputs1
    ) {
    %1 : Tuple[Tensor(F32),Tensor(I64)]TupleShape((64, 3, 64, 256), (64, 25)) = Primitive::MakeTuple{prim_type=1}(%para583, %para584)    #(Tensor(F32)[64, 3, 64, 256], Tensor(I64)[64, 25]) #scope: Default
      # In file /home/mindspore/anaconda3/envs/ms1.9/lib/python3.7/site-packages/mindspore/nn/wrap/cell_wrapper.py:379/    def construct(self, *inputs):/#[CNode]71

#------------------------> 2
    %2 = UnpackCall::unpack_call(FuncGraph::fg_37, %1)    #(FuncNoShape, Tuple[Tensor(F32),Tensor(I64)]TupleShape((64, 3, 64, 256), (64, 25)))    # fg_37=WithLossCell.37 #scope: Default
      # In file /home/mindspore/anaconda3/envs/ms1.9/lib/python3.7/site-packages/mindspore/nn/wrap/cell_wrapper.py:380/        loss = self.network(*inputs)/#loss
    %3 = Primitive::getattr{prim_type=1}(%2, "dtype")    #(Undefined, Undefined) #scope: Default
      # In file /home/mindspore/anaconda3/envs/ms1.9/lib/python3.7/site-packages/mindspore/nn/wrap/cell_wrapper.py:381/        sens = F.fill(loss.dtype, loss.shape, self.sens)/#[CNode]72
    %4 = Primitive::getattr{prim_type=1}(%2, "shape")    #(Undefined, Undefined) #scope: Default
      # In file /home/mindspore/anaconda3/envs/ms1.9/lib/python3.7/site-packages/mindspore/nn/wrap/cell_wrapper.py:381/        sens = F.fill(loss.dtype, loss.shape, self.sens)/#[CNode]73
    %5 = FuncGraph::fg_74(%3, %4, I64(1024))    #(Undefined, Undefined, Undefined)    # fg_74=fill.74 #scope: Default
      # In file /home/mindspore/anaconda3/envs/ms1.9/lib/python3.7/site-packages/mindspore/nn/wrap/cell_wrapper.py:381/        sens = F.fill(loss.dtype, loss.shape, self.sens)/#sens
    %6 = DoSignaturePrimitive::S-Prim-MakeTuple{prim_type=1}(%5)    #(Undefined) #scope: Default
      # In file /home/mindspore/anaconda3/envs/ms1.9/lib/python3.7/site-packages/mindspore/nn/wrap/cell_wrapper.py:382/        grads = self.grad(self.network, self.weights)(*inputs, sens)/#[CNode]75
    %7 = UnpackGraphPrimitive::UnpackGraph{prim_type=1}(FuncGraph::fg_37, %1, %6)    #(Undefined, Tuple[Tensor(F32),Tensor(I64)]TupleShape((64, 3, 64, 256), (64, 25)), Undefined)    # fg_37=WithLossCell.37 #scope: Default
      # In file /home/mindspore/anaconda3/envs/ms1.9/lib/python3.7/site-packages/mindspore/nn/wrap/cell_wrapper.py:382/        grads = self.grad(self.network, self.weights)(*inputs, sens)/#grads
    %8 = Primitive::MakeTuple{prim_type=1}(%para3, %para4, %para5, %para6, %para7, %para8, %para9, %para10, %para11, %para12, %para13, %para14, %para15, %para16, %para17, %para18, %para19, %para20, %para21, %para22, %para23, %para24, %para25, %para26, %para27, %para28, %para29, %para30, %para31, %para32, %para33, %para34, %para35, %para36, %para37, %para38, %para39, %para40, %para41, %para42, %para43, %para44, %para45, %para46, %para47, %para48, %para49, %para50, %para51, %para52, %para53, %para54, %para55, %para56, %para57, %para58, %para59, %para60, %para61, %para62, %para63, %para64, %para65, %para66, %para67, %para68, %para69, %para70, %para71, %para72, %para73, %para74, %para75, %para76, %para77, %para78, %para79, %para80, %para81, %para82, %para83, %para84, %para85, %para86, %para87, %para88, %para89, %para90, %para91, %para92, %para93, %para94, %para95, %para96, %para97, %para98, %para99, %para100, %para101, %para102, %para103, %para104, %para105, %para106, %para107, %para108, %para109, %para110, %para111, %para112, %para113, %para114, %para115, %para116, %para117, %para118, %para119, %para120, %para121, %para122, %para123, %para124, %para125, %para126, %para127, %para128, %para129, %para130, %para131, %para132, %para133, %para134, %para135, %para136, %para137, %para138, %para139, %para140, %para141, %para142, %para143, %para144, %para145, %para146, %para147, %para148, %para149, %para150, %para151, %para152, %para153, %para154, %para155, %para156, %para157, %para158, %para159, %para160, %para161, %para162, %para163, %para164, %para165, %para166, %para167, %para168, %para169, %para170, %para171, %para172, %para173, %para174, %para175, %para176, %para177, %para178, %para179, %para180, %para181, %para182, %para183, %para184, %para185, %para186, %para187, %para188)    #(Ref[Tensor(F32)][32, 3, 3, 3], Ref[Tensor(F32)][32], Ref[Tensor(F32)][32], Ref[Tensor(F32)][64, 32, 3, 3], Ref[Tensor(F32)][64], Ref[Tensor(F32)][64], Ref[Tensor(F32)][128, 64, 3, 3], Ref[Tensor(F32)][128], Ref[Tensor(F32)][128], Ref[Tensor(F32)][256, 128, 3, 3], Ref[Tensor(F32)][256], Ref[Tensor(F32)][256], Ref[Tensor(F32)][256, 256, 3, 3], Ref[Tensor(F32)][256], Ref[Tensor(F32)][256], Ref[Tensor(F32)][256, 256, 3, 3], Ref[Tensor(F32)][256], Ref[Tensor(F32)][256], Ref[Tensor(F32)][512, 512], Ref[Tensor(F32)][512], Ref[Tensor(F32)][512], Ref[Tensor(F32)][512], Ref[Tensor(F32)][40, 512], Ref[Tensor(F32)][40], Ref[Tensor(F32)][1, 200, 64], Ref[Tensor(F32)][32, 3, 3, 3], Ref[Tensor(F32)][32], Ref[Tensor(F32)][32], Ref[Tensor(F32)][64, 32, 3, 3], Ref[Tensor(F32)][64], Ref[Tensor(F32)][64], Ref[Tensor(F32)][64], Ref[Tensor(F32)][64], Ref[Tensor(F32)][192, 64], Ref[Tensor(F32)][192], Ref[Tensor(F32)][64, 64], Ref[Tensor(F32)][64], Ref[Tensor(F32)][64], Ref[Tensor(F32)][64], Ref[Tensor(F32)][256, 64], Ref[Tensor(F32)][256], Ref[Tensor(F32)][64, 256], Ref[Tensor(F32)][64], Ref[Tensor(F32)][64], Ref[Tensor(F32)][64], Ref[Tensor(F32)][192, 64], Ref[Tensor(F32)][192], Ref[Tensor(F32)][64, 64], Ref[Tensor(F32)][64], Ref[Tensor(F32)][64], Ref[Tensor(F32)][64], Ref[Tensor(F32)][256, 64], Ref[Tensor(F32)][256], Ref[Tensor(F32)][64, 256], Ref[Tensor(F32)][64], Ref[Tensor(F32)][64], Ref[Tensor(F32)][64], Ref[Tensor(F32)][192, 64], Ref[Tensor(F32)][192], Ref[Tensor(F32)][64, 64], Ref[Tensor(F32)][64], Ref[Tensor(F32)][64], Ref[Tensor(F32)][64], Ref[Tensor(F32)][256, 64], Ref[Tensor(F32)][256], Ref[Tensor(F32)][64, 256], Ref[Tensor(F32)][64], Ref[Tensor(F32)][128, 64, 3, 3], Ref[Tensor(F32)][128], Ref[Tensor(F32)][128], Ref[Tensor(F32)][128], Ref[Tensor(F32)][128], Ref[Tensor(F32)][384, 128], Ref[Tensor(F32)][384], Ref[Tensor(F32)][128, 128], Ref[Tensor(F32)][128], Ref[Tensor(F32)][128], Ref[Tensor(F32)][128], Ref[Tensor(F32)][512, 128], Ref[Tensor(F32)][512], Ref[Tensor(F32)][128, 512], Ref[Tensor(F32)][128], Ref[Tensor(F32)][128], Ref[Tensor(F32)][128], Ref[Tensor(F32)][384, 128], Ref[Tensor(F32)][384], Ref[Tensor(F32)][128, 128], Ref[Tensor(F32)][128], Ref[Tensor(F32)][128], Ref[Tensor(F32)][128], Ref[Tensor(F32)][512, 128], Ref[Tensor(F32)][512], Ref[Tensor(F32)][128, 512], Ref[Tensor(F32)][128], Ref[Tensor(F32)][128], Ref[Tensor(F32)][128], Ref[Tensor(F32)][384, 128], Ref[Tensor(F32)][384], Ref[Tensor(F32)][128, 128], Ref[Tensor(F32)][128], Ref[Tensor(F32)][128], Ref[Tensor(F32)][128], Ref[Tensor(F32)][512, 128], Ref[Tensor(F32)][512], Ref[Tensor(F32)][128, 512], Ref[Tensor(F32)][128], Ref[Tensor(F32)][128], Ref[Tensor(F32)][128], Ref[Tensor(F32)][384, 128], Ref[Tensor(F32)][384], Ref[Tensor(F32)][128, 128], Ref[Tensor(F32)][128], Ref[Tensor(F32)][128], Ref[Tensor(F32)][128], Ref[Tensor(F32)][512, 128], Ref[Tensor(F32)][512], Ref[Tensor(F32)][128, 512], Ref[Tensor(F32)][128], Ref[Tensor(F32)][128], Ref[Tensor(F32)][128], Ref[Tensor(F32)][384, 128], Ref[Tensor(F32)][384], Ref[Tensor(F32)][128, 128], Ref[Tensor(F32)][128], Ref[Tensor(F32)][128], Ref[Tensor(F32)][128], Ref[Tensor(F32)][512, 128], Ref[Tensor(F32)][512], Ref[Tensor(F32)][128, 512], Ref[Tensor(F32)][128], Ref[Tensor(F32)][128], Ref[Tensor(F32)][128], Ref[Tensor(F32)][384, 128], Ref[Tensor(F32)][384], Ref[Tensor(F32)][128, 128], Ref[Tensor(F32)][128], Ref[Tensor(F32)][128], Ref[Tensor(F32)][128], Ref[Tensor(F32)][512, 128], Ref[Tensor(F32)][512], Ref[Tensor(F32)][128, 512], Ref[Tensor(F32)][128], Ref[Tensor(F32)][256, 128, 3, 3], Ref[Tensor(F32)][256], Ref[Tensor(F32)][256], Ref[Tensor(F32)][256], Ref[Tensor(F32)][256], Ref[Tensor(F32)][768, 256], Ref[Tensor(F32)][768], Ref[Tensor(F32)][256, 256], Ref[Tensor(F32)][256], Ref[Tensor(F32)][256], Ref[Tensor(F32)][256], Ref[Tensor(F32)][1024, 256], Ref[Tensor(F32)][1024], Ref[Tensor(F32)][256, 1024], Ref[Tensor(F32)][256], Ref[Tensor(F32)][256], Ref[Tensor(F32)][256], Ref[Tensor(F32)][768, 256], Ref[Tensor(F32)][768], Ref[Tensor(F32)][256, 256], Ref[Tensor(F32)][256], Ref[Tensor(F32)][256], Ref[Tensor(F32)][256], Ref[Tensor(F32)][1024, 256], Ref[Tensor(F32)][1024], Ref[Tensor(F32)][256, 1024], Ref[Tensor(F32)][256], Ref[Tensor(F32)][256], Ref[Tensor(F32)][256], Ref[Tensor(F32)][768, 256], Ref[Tensor(F32)][768], Ref[Tensor(F32)][256, 256], Ref[Tensor(F32)][256], Ref[Tensor(F32)][256], Ref[Tensor(F32)][256], Ref[Tensor(F32)][1024, 256], Ref[Tensor(F32)][1024], Ref[Tensor(F32)][256, 1024], Ref[Tensor(F32)][256], Ref[Tensor(F32)][192, 256, 1, 1], Ref[Tensor(F32)][256], Ref[Tensor(F32)][256], Ref[Tensor(F32)][37, 192], Ref[Tensor(F32)][37]) #scope: Default
      # In file /home/mindspore/anaconda3/envs/ms1.9/lib/python3.7/site-packages/mindspore/nn/wrap/cell_wrapper.py:382/        grads = self.grad(self.network, self.weights)(*inputs, sens)/#[CNode]76
    %9 = DoSignaturePrimitive::S-Prim-grad{prim_type=1}(%7, %8)    #(Undefined, Undefined) #scope: Default
      # In file /home/mindspore/anaconda3/envs/ms1.9/lib/python3.7/site-packages/mindspore/nn/wrap/cell_wrapper.py:382/        grads = self.grad(self.network, self.weights)(*inputs, sens)/#grads
    %10 = UnpackCall::unpack_call(%9, %1, %6)    #(Undefined, Tuple[Tensor(F32),Tensor(I64)]TupleShape((64, 3, 64, 256), (64, 25)), Undefined) #scope: Default
      # In file /home/mindspore/anaconda3/envs/ms1.9/lib/python3.7/site-packages/mindspore/nn/wrap/cell_wrapper.py:382/        grads = self.grad(self.network, self.weights)(*inputs, sens)/#grads
    %11 = DoSignaturePrimitive::S-Prim-identity{prim_type=1}[side_effect_propagate=I64(1)](%10)    #(Undefined) #scope: Default
      # In file /home/mindspore/anaconda3/envs/ms1.9/lib/python3.7/site-packages/mindspore/nn/wrap/cell_wrapper.py:383/        grads = self.grad_reducer(grads)/#grads
    %12 = FuncGraph::fg_77(%11)    #(Undefined)    # fg_77=AdamWeightDecay.77 #scope: Default
      # In file /home/mindspore/anaconda3/envs/ms1.9/lib/python3.7/site-packages/mindspore/nn/wrap/cell_wrapper.py:384/        loss = F.depend(loss, self.optimizer(grads))/#[CNode]78
    %13 = DoSignaturePrimitive::S-Prim-Depend{prim_type=1}[side_effect_propagate=I64(1)](%2, %12)    #(Undefined, Undefined) #scope: Default
      # In file /home/mindspore/anaconda3/envs/ms1.9/lib/python3.7/site-packages/mindspore/nn/wrap/cell_wrapper.py:384/        loss = F.depend(loss, self.optimizer(grads))/#loss
    Primitive::Return{prim_type=1}(%13)    #(Undefined) #scope: Default
      # In file /home/mindspore/anaconda3/envs/ms1.9/lib/python3.7/site-packages/mindspore/nn/wrap/cell_wrapper.py:385/        return loss/#[CNode]79
}
# order:
#   1: @Default.33:loss{[0]: ValueNode<UnpackCall> unpack_call.80, [1]: ValueNode<FuncGraph> WithLossCell.37, [2]: [CNode]71}
#   2: @Default.33:[CNode]72{[0]: ValueNode<Primitive> getattr, [1]: loss, [2]: ValueNode<StringImm> dtype}
#   3: @Default.33:[CNode]73{[0]: ValueNode<Primitive> getattr, [1]: loss, [2]: ValueNode<StringImm> shape}
#   4: @Default.33:sens{[0]: ValueNode<FuncGraph> fill.74, [1]: [CNode]72, [2]: [CNode]73, [3]: ValueNode<Int64Imm> 1024}
#   5: @Default.33:[CNode]75{[0]: ValueNode<DoSignaturePrimitive> S-Prim-MakeTuple, [1]: sens}
#   6: @Default.33:grads{[0]: ValueNode<UnpackGraphPrimitive> UnpackGraph, [1]: ValueNode<FuncGraph> WithLossCell.37, [2]: [CNode]71, [3]: [CNode]75}
#   7: @Default.33:grads{[0]: ValueNode<DoSignaturePrimitive> S-Prim-grad, [1]: grads, [2]: [CNode]76}
#   8: @Default.33:grads{[0]: ValueNode<UnpackCall> unpack_call.81, [1]: grads, [2]: [CNode]71, [3]: [CNode]75}
#   9: @Default.33:grads{[0]: ValueNode<DoSignaturePrimitive> S-Prim-identity, [1]: grads}
#  10: @Default.33:[CNode]78{[0]: ValueNode<FuncGraph> AdamWeightDecay.77, [1]: grads}
#  11: @Default.33:loss{[0]: ValueNode<DoSignaturePrimitive> S-Prim-Depend, [1]: loss, [2]: [CNode]78}
#  12: @Default.33:[CNode]79{[0]: ValueNode<Primitive> Return, [1]: loss}


# [No.4] UnpackCall.34

funcgraph fg_34(
        %para585 : FuncNoShape    # 35
        , %para586 : Tuple[Tensor(F32),Tensor(I64)]TupleShape((64, 3, 64, 256), (64, 25))    # 36
    ) {
    %1 : Tensor(F32)[64, 3, 64, 256] = Primitive::TupleGetItem{prim_type=1}(%para586, I64(0))    #(Tuple[Tensor(F32),Tensor(I64)]TupleShape((64, 3, 64, 256), (64, 25)), I64NoShape) #scope: Default
#82
    %2 : Tensor(I64)[64, 25] = Primitive::TupleGetItem{prim_type=1}(%para586, I64(1))    #(Tuple[Tensor(F32),Tensor(I64)]TupleShape((64, 3, 64, 256), (64, 25)), I64NoShape) #scope: Default
#83

#------------------------> 3
    %3 = %para585(%1, %2)    #(Tensor(F32)[64, 3, 64, 256], Tensor(I64)[64, 25]) #scope: Default
#84
    Primitive::Return{prim_type=1}(%3)    #(Undefined) #scope: Default
#85
}
# order:
#   1: @UnpackCall.34:84{[0]: 35, [1]: 82, [2]: 83}
#   2: @UnpackCall.34:85{[0]: ValueNode<Primitive> Return, [1]: 84}


# [No.5] WithLossCell.37
# In file /home/mindspore/anaconda3/envs/ms1.9/lib/python3.7/site-packages/mindspore/train/amp.py:243/        def construct(self, data, label):/
funcgraph fg_37[fg_29](
        %para587 : Tensor(F32)[64, 3, 64, 256]    # data
        , %para588 : Tensor(I64)[64, 25]    # label
    ) {

#------------------------> 4
    %1 = FuncGraph::fg_86(%para587)    #(Tensor(F32)[64, 3, 64, 256])    # fg_86=BaseModel.86 #scope: Default/network-WithLossCell
      # In file /home/mindspore/anaconda3/envs/ms1.9/lib/python3.7/site-packages/mindspore/train/amp.py:244/            out = self._backbone(data)/#out
    %2 = DoSignaturePrimitive::S-Prim-MixedPrecisionCast{prim_type=1}[output_names=["output"], input_names=["dst_dtype", "input_x"]](F32, %1)    #(Undefined, Undefined) #scope: Default/network-WithLossCell
      # In file /home/mindspore/anaconda3/envs/ms1.9/lib/python3.7/site-packages/mindspore/train/amp.py:246/            return self._loss_fn(F.mixed_precision_cast(mstype.float32, out), label)/#[CNode]87
    %3 = DoSignaturePrimitive::S-Prim-MixedPrecisionCast{prim_type=1}[output_names=["output"], input_names=["dst_dtype", "input_x"]](F32, %para588)    #(Undefined, Tensor(I64)[64, 25]) #scope: Default/network-WithLossCell
      # In file /home/mindspore/anaconda3/envs/ms1.9/lib/python3.7/site-packages/mindspore/train/amp.py:245/            label = F.mixed_precision_cast(mstype.float32, label)/#label
    %4 = FuncGraph::fg_88(%2, %3)    #(Undefined, Undefined)    # fg_88=CTCLoss.88 #scope: Default/network-WithLossCell
      # In file /home/mindspore/anaconda3/envs/ms1.9/lib/python3.7/site-packages/mindspore/train/amp.py:246/            return self._loss_fn(F.mixed_precision_cast(mstype.float32, out), label)/#[CNode]89
    Primitive::Return{prim_type=1}(%4)    #(Undefined) #scope: Default/network-WithLossCell
      # In file /home/mindspore/anaconda3/envs/ms1.9/lib/python3.7/site-packages/mindspore/train/amp.py:246/            return self._loss_fn(F.mixed_precision_cast(mstype.float32, out), label)/#[CNode]90
}
# order:
#   1: @WithLossCell.37:out{[0]: ValueNode<FuncGraph> BaseModel.86, [1]: data}
#   2: @WithLossCell.37:label{[0]: ValueNode<DoSignaturePrimitive> S-Prim-MixedPrecisionCast, [1]: ValueNode<Float> Float32, [2]: label}
#   3: @WithLossCell.37:[CNode]87{[0]: ValueNode<DoSignaturePrimitive> S-Prim-MixedPrecisionCast, [1]: ValueNode<Float> Float32, [2]: out}
#   4: @WithLossCell.37:[CNode]89{[0]: ValueNode<FuncGraph> CTCLoss.88, [1]: [CNode]87, [2]: label}
#   5: @WithLossCell.37:[CNode]90{[0]: ValueNode<Primitive> Return, [1]: [CNode]89}


# [No.6] BaseModel.38
# In file /home/mindspore/lby_spencer/svtr_mindspore/svtr_mindspore/modeling/architectures/base_model.py:67/    def construct(self, x, data=None):/
funcgraph fg_38[fg_29](
        %para589 : Tensor(F32)[64, 3, 64, 256]    # x
    ) {
    %1 : BoolNoShape = FuncGraph::fg_10(Bool(1))    #(BoolNoShape)    # fg_10=bool_.10 #scope: Default/network-WithLossCell/_backbone-BaseModel
      # In file /home/mindspore/lby_spencer/svtr_mindspore/svtr_mindspore/modeling/architectures/base_model.py:70/        if self.use_transform:/#[CNode]91
    %2 : FuncNoShape = Primitive::Switch{prim_type=1}(%1, FuncGraph::fg_39, FuncGraph::fg_92)    #(BoolNoShape, FuncNoShape, FuncNoShape)    # fg_39=BaseModel.39, fg_92=BaseModel.92 #scope: Default/network-WithLossCell/_backbone-BaseModel
      # In file /home/mindspore/lby_spencer/svtr_mindspore/svtr_mindspore/modeling/architectures/base_model.py:70/        if self.use_transform:/#[CNode]93

#------------------------> 5
    %3 = %2() #scope: Default/network-WithLossCell/_backbone-BaseModel
      # In file /home/mindspore/lby_spencer/svtr_mindspore/svtr_mindspore/modeling/architectures/base_model.py:70/        if self.use_transform:/#[CNode]94
    %4 = FuncGraph::fg_95(%3)    #(Undefined)    # fg_95=BaseModel.95 #scope: Default/network-WithLossCell
      # In file /home/mindspore/anaconda3/envs/ms1.9/lib/python3.7/site-packages/mindspore/train/amp.py:244/            out = self._backbone(data)/#[CNode]96
    Primitive::Return{prim_type=1}(%4)    #(Undefined) #scope: Default/network-WithLossCell/_backbone-BaseModel
      # In file /home/mindspore/lby_spencer/svtr_mindspore/svtr_mindspore/modeling/architectures/base_model.py:70/        if self.use_transform:/#[CNode]97
}
# order:
#   1: @BaseModel.38:data{[0]: ValueNode<Primitive> MixedPrecisionCast, [1]: ValueNode<Float> Float16, [2]: ValueNode<None> None}
#   2: @BaseModel.38:[CNode]98{[0]: ValueNode<Primitive> MixedPrecisionCast, [1]: ValueNode<Float> Float16, [2]: x}
#   3: @BaseModel.38:[CNode]99{[0]: ValueNode<DoSignaturePrimitive> S-Prim-MakeTuple}
#   4: @BaseModel.38:[CNode]100{[0]: ValueNode<DoSignaturePrimitive> S-Prim-MakeTuple}
#   5: @BaseModel.38:[CNode]101{[0]: ValueNode<DoSignaturePrimitive> S-Prim-make_dict, [1]: [CNode]99, [2]: [CNode]100}
#   6: @BaseModel.38:y{[0]: ValueNode<Primitive> PyInterpret, [1]: ValueNode<Script> 'dict()', [2]: ValueNode<ValueDictionary> {'dict': class 'dict'}, [3]: [CNode]101}
#   7: @BaseModel.38:[CNode]91{[0]: ValueNode<FuncGraph> bool_.10, [1]: ValueNode<BoolImm> true}
#   8: @BaseModel.38:[CNode]93{[0]: ValueNode<Primitive> Switch, [1]: [CNode]91, [2]: ValueNode<FuncGraph> BaseModel.39, [3]: ValueNode<FuncGraph> BaseModel.92}
#   9: @BaseModel.38:[CNode]94{[0]: [CNode]93}
#  10: @BaseModel.38:[CNode]96{[0]: ValueNode<FuncGraph> BaseModel.95, [1]: [CNode]94}
#  11: @BaseModel.38:[CNode]97{[0]: ValueNode<Primitive> Return, [1]: [CNode]96}


# [No.7] BaseModel.39
# In file /home/mindspore/lby_spencer/svtr_mindspore/svtr_mindspore/modeling/architectures/base_model.py:70/        if self.use_transform:/
funcgraph fg_39[fg_38](
) {
    %1 : $(BaseModel.38):Tensor(F16)[64, 3, 64, 256] = Primitive::MixedPrecisionCast{prim_type=1}(F16, %para589)    #(TypeTypeNoShape, Tensor(F32)[64, 3, 64, 256]) #scope: Default/network-WithLossCell/_backbone-BaseModel
      # In file /home/mindspore/lby_spencer/svtr_mindspore/svtr_mindspore/modeling/architectures/base_model.py:67/    def construct(self, x, data=None):/#[CNode]98

#------------------------> 6
    %2 = FuncGraph::fg_40(%1)    #(Tensor(F16)[64, 3, 64, 256])    # fg_40=STN_ON.40 #scope: Default/network-WithLossCell/_backbone-BaseModel
      # In file /home/mindspore/lby_spencer/svtr_mindspore/svtr_mindspore/modeling/architectures/base_model.py:72/            x = self.transform(x)/#x
    %3 = FuncGraph::fg_102("before transformer:", %1)    #(Undefined, Tensor(F16)[64, 3, 64, 256])    # fg_102=print_.102 #scope: Default/network-WithLossCell/_backbone-BaseModel
      # In file /home/mindspore/lby_spencer/svtr_mindspore/svtr_mindspore/modeling/architectures/base_model.py:71/            print("before transformer:",x)    #before transformer: [64, 3, 64, 256]/#[CNode]103
    %4 = FuncGraph::fg_102("after transformer:", %2)    #(Undefined, Undefined)    # fg_102=print_.102 #scope: Default/network-WithLossCell/_backbone-BaseModel
      # In file /home/mindspore/lby_spencer/svtr_mindspore/svtr_mindspore/modeling/architectures/base_model.py:73/            print("after transformer:", x)   #after transformer: [64, 3, 32, 100]/#[CNode]104
    %5 = Primitive::MakeTuple{prim_type=1}(%3, %4)    #(Undefined, Undefined) #scope: Default/network-WithLossCell/_backbone-BaseModel
      # In file /home/mindspore/anaconda3/envs/ms1.9/lib/python3.7/site-packages/mindspore/train/amp.py:244/            out = self._backbone(data)/#[CNode]105
    %6 = Primitive::stop_gradient{prim_type=1}(%5)    #(Undefined) #scope: Default/network-WithLossCell/_backbone-BaseModel
      # In file /home/mindspore/anaconda3/envs/ms1.9/lib/python3.7/site-packages/mindspore/train/amp.py:244/            out = self._backbone(data)/#[CNode]106
    %7 = Primitive::Depend{prim_type=1}[side_effect_propagate=I64(1)](%2, %6)    #(Undefined, Undefined) #scope: Default/network-WithLossCell
      # In file /home/mindspore/anaconda3/envs/ms1.9/lib/python3.7/site-packages/mindspore/train/amp.py:244/            out = self._backbone(data)/#[CNode]107
    Primitive::Return{prim_type=1}(%7)    #(Undefined) #scope: Default/network-WithLossCell/_backbone-BaseModel
      # In file /home/mindspore/lby_spencer/svtr_mindspore/svtr_mindspore/modeling/architectures/base_model.py:70/        if self.use_transform:/#[CNode]108
}
# order:
#   1: @BaseModel.39:[CNode]103{[0]: ValueNode<FuncGraph> print_.102, [1]: ValueNode<StringImm> before transformer:, [2]: [CNode]98}
#   2: @BaseModel.39:x{[0]: ValueNode<FuncGraph> STN_ON.40, [1]: [CNode]98}
#   3: @BaseModel.39:[CNode]104{[0]: ValueNode<FuncGraph> print_.102, [1]: ValueNode<StringImm> after transformer:, [2]: x}
#   4: @BaseModel.39:[CNode]108{[0]: ValueNode<Primitive> Return, [1]: [CNode]107}


# [No.8] STN_ON.40
# In file /home/mindspore/lby_spencer/svtr_mindspore/svtr_mindspore/modeling/transforms/stn.py:134/    def construct(self, image):/
funcgraph fg_40[fg_29](
        %para590 : Tensor(F16)[64, 3, 64, 256]    # image
    ) {
    %1 : Tensor(F16)[64, 3, 64, 256] = Primitive::MixedPrecisionCast{prim_type=1}(F16, %para590)    #(TypeTypeNoShape, Tensor(F16)[64, 3, 64, 256]) #scope: Default/network-WithLossCell/_backbone-BaseModel/transform-STN_ON
      # In file /home/mindspore/lby_spencer/svtr_mindspore/svtr_mindspore/modeling/transforms/stn.py:134/    def construct(self, image):/#[CNode]109
    %2 : Tuple[Tensor(F16)]TupleShape((64, 3, 64, 256)) = DoSignaturePrimitive::S-Prim-MakeTuple{prim_type=1}(%1)    #(Tensor(F16)[64, 3, 64, 256]) #scope: Default/network-WithLossCell/_backbone-BaseModel/transform-STN_ON
      # In file /home/mindspore/lby_spencer/svtr_mindspore/svtr_mindspore/modeling/transforms/stn.py:135/        stn_input = ops.interpolate(/#[CNode]110
    %3 : Tuple[String*2]TupleShape(NoShape, NoShape) = DoSignaturePrimitive::S-Prim-MakeTuple{prim_type=1}("sizes", "mode")    #(StringNoShape, StringNoShape) #scope: Default/network-WithLossCell/_backbone-BaseModel/transform-STN_ON
      # In file /home/mindspore/lby_spencer/svtr_mindspore/svtr_mindspore/modeling/transforms/stn.py:135/        stn_input = ops.interpolate(/#[CNode]111
    %4 : Tuple[I64*2]TupleShape(NoShape, NoShape) = ClassType([I64(32), I64(64)])    #(List[I64*2]ListShape[NoShape, NoShape]) #scope: Default/network-WithLossCell/_backbone-BaseModel/transform-STN_ON
      # In file /home/mindspore/lby_spencer/svtr_mindspore/svtr_mindspore/modeling/transforms/stn.py:136/            image, sizes=tuple(self.tps_inputsize), mode="bilinear")/#[CNode]112
    %5 : Tuple[Tuple[I64*2],String]TupleShape(TupleShape(NoShape, NoShape), NoShape) = DoSignaturePrimitive::S-Prim-MakeTuple{prim_type=1}(%4, "bilinear")    #(Tuple[I64*2]TupleShape(NoShape, NoShape), StringNoShape) #scope: Default/network-WithLossCell/_backbone-BaseModel/transform-STN_ON
      # In file /home/mindspore/lby_spencer/svtr_mindspore/svtr_mindspore/modeling/transforms/stn.py:135/        stn_input = ops.interpolate(/#[CNode]113
    %6 : Dictionary[[sizes,mode,],[Tuple[Int64*2],String]]NoShape = DoSignaturePrimitive::S-Prim-make_dict{prim_type=1}(%3, %5)    #(Tuple[String*2]TupleShape(NoShape, NoShape), Tuple[Tuple[I64*2],String]TupleShape(TupleShape(NoShape, NoShape), NoShape)) #scope: Default/network-WithLossCell/_backbone-BaseModel/transform-STN_ON
      # In file /home/mindspore/lby_spencer/svtr_mindspore/svtr_mindspore/modeling/transforms/stn.py:135/        stn_input = ops.interpolate(/#[CNode]114
    %7 : Tensor(F16)[64, 3, 32, 64] = UnpackCall::unpack_call(FuncGraph::fg_115, %2, %6)    #(FuncNoShape, Tuple[Tensor(F16)]TupleShape((64, 3, 64, 256)), Dictionary[[sizes,mode,],[Tuple[Int64*2],String]]NoShape)    # fg_115=interpolate.115 #scope: Default/network-WithLossCell/_backbone-BaseModel/transform-STN_ON
      # In file /home/mindspore/lby_spencer/svtr_mindspore/svtr_mindspore/modeling/transforms/stn.py:135/        stn_input = ops.interpolate(/#stn_input
    %8 : Tuple[Tensor(F16)*2]TupleShape((64, 512), (64, 20, 2)) = FuncGraph::fg_116(%7)    #(Tensor(F16)[64, 3, 32, 64])    # fg_116=STN.116 #scope: Default/network-WithLossCell/_backbone-BaseModel/transform-STN_ON
      # In file /home/mindspore/lby_spencer/svtr_mindspore/svtr_mindspore/modeling/transforms/stn.py:137/        stn_img_feat, ctrl_points = self.stn_head(stn_input)/#[CNode]117
    %9 : Tensor(F16)[64, 512] = DoSignaturePrimitive::S-Prim-getitem{prim_type=1}(%8, I64(0))    #(Tuple[Tensor(F16)*2]TupleShape((64, 512), (64, 20, 2)), I64NoShape) #scope: Default/network-WithLossCell/_backbone-BaseModel/transform-STN_ON
      # In file /home/mindspore/lby_spencer/svtr_mindspore/svtr_mindspore/modeling/transforms/stn.py:137/        stn_img_feat, ctrl_points = self.stn_head(stn_input)/#stn_img_feat
    %10 : Tensor(F16)[64, 512] = Primitive::stop_gradient{prim_type=1}(%9)    #(Tensor(F16)[64, 512]) #scope: Default/network-WithLossCell/_backbone-BaseModel/transform-STN_ON
      # In file /home/mindspore/lby_spencer/svtr_mindspore/svtr_mindspore/modeling/architectures/base_model.py:72/            x = self.transform(x)/#[CNode]118
    %11 : Tensor(F16)[64, 20, 2] = DoSignaturePrimitive::S-Prim-getitem{prim_type=1}(%8, I64(1))    #(Tuple[Tensor(F16)*2]TupleShape((64, 512), (64, 20, 2)), I64NoShape) #scope: Default/network-WithLossCell/_backbone-BaseModel/transform-STN_ON
      # In file /home/mindspore/lby_spencer/svtr_mindspore/svtr_mindspore/modeling/transforms/stn.py:137/        stn_img_feat, ctrl_points = self.stn_head(stn_input)/#ctrl_points

#------------------------> 7
    %12 = FuncGraph::fg_41(%1, %11)    #(Tensor(F16)[64, 3, 64, 256], Tensor(F16)[64, 20, 2])    # fg_41=TPSSpatialTransformer.41 #scope: Default/network-WithLossCell/_backbone-BaseModel/transform-STN_ON
      # In file /home/mindspore/lby_spencer/svtr_mindspore/svtr_mindspore/modeling/transforms/stn.py:139/        x, _ = self.tps(image, ctrl_points)/#[CNode]119
    %13 = DoSignaturePrimitive::S-Prim-getitem{prim_type=1}(%12, I64(0))    #(Undefined, Undefined) #scope: Default/network-WithLossCell/_backbone-BaseModel/transform-STN_ON
      # In file /home/mindspore/lby_spencer/svtr_mindspore/svtr_mindspore/modeling/transforms/stn.py:139/        x, _ = self.tps(image, ctrl_points)/#x
    %14 = Primitive::Depend{prim_type=1}[side_effect_propagate=I64(1)](%13, %10)    #(Undefined, Tensor(F16)[64, 512]) #scope: Default/network-WithLossCell/_backbone-BaseModel/transform-STN_ON
      # In file /home/mindspore/lby_spencer/svtr_mindspore/svtr_mindspore/modeling/architectures/base_model.py:72/            x = self.transform(x)/#[CNode]120
    Primitive::Return{prim_type=1}(%14)    #(Undefined) #scope: Default/network-WithLossCell/_backbone-BaseModel/transform-STN_ON
      # In file /home/mindspore/lby_spencer/svtr_mindspore/svtr_mindspore/modeling/transforms/stn.py:140/        return x/#[CNode]121
}
# order:
#   1: @STN_ON.40:[CNode]109{[0]: ValueNode<Primitive> MixedPrecisionCast, [1]: ValueNode<Float> Float16, [2]: image}
#   2: @STN_ON.40:[CNode]110{[0]: ValueNode<DoSignaturePrimitive> S-Prim-MakeTuple, [1]: [CNode]109}
#   3: @STN_ON.40:[CNode]111{[0]: ValueNode<DoSignaturePrimitive> S-Prim-MakeTuple, [1]: ValueNode<StringImm> sizes, [2]: ValueNode<StringImm> mode}
#   4: @STN_ON.40:[CNode]113{[0]: ValueNode<DoSignaturePrimitive> S-Prim-MakeTuple, [1]: [CNode]112, [2]: ValueNode<StringImm> bilinear}
#   5: @STN_ON.40:[CNode]114{[0]: ValueNode<DoSignaturePrimitive> S-Prim-make_dict, [1]: [CNode]111, [2]: [CNode]113}
#   6: @STN_ON.40:stn_input{[0]: ValueNode<UnpackCall> unpack_call.122, [1]: ValueNode<FuncGraph> interpolate.115, [2]: [CNode]110, [3]: [CNode]114}
#   7: @STN_ON.40:[CNode]117{[0]: ValueNode<FuncGraph> STN.116, [1]: stn_input}
#   8: @STN_ON.40:stn_img_feat{[0]: ValueNode<DoSignaturePrimitive> S-Prim-getitem, [1]: [CNode]117, [2]: ValueNode<Int64Imm> 0}
#   9: @STN_ON.40:ctrl_points{[0]: ValueNode<DoSignaturePrimitive> S-Prim-getitem, [1]: [CNode]117, [2]: ValueNode<Int64Imm> 1}
#  10: @STN_ON.40:[CNode]119{[0]: ValueNode<FuncGraph> TPSSpatialTransformer.41, [1]: [CNode]109, [2]: ctrl_points}
#  11: @STN_ON.40:x{[0]: ValueNode<DoSignaturePrimitive> S-Prim-getitem, [1]: [CNode]119, [2]: ValueNode<Int64Imm> 0}
#  12: @STN_ON.40:[CNode]121{[0]: ValueNode<Primitive> Return, [1]: [CNode]120}


# [No.9] TPSSpatialTransformer.41
# In file /home/mindspore/lby_spencer/svtr_mindspore/svtr_mindspore/modeling/transforms/tps_spatical_transformer.py:147/    def construct(self, input, source_control_points):/
funcgraph fg_41(
        %para591 : Tensor(F16)[64, 3, 64, 256]    # input
        , %para592 : Tensor(F16)[64, 20, 2]    # source_control_points
    ) {
    %1 : Tensor(F16)[64, 20, 2] = Primitive::MixedPrecisionCast{prim_type=1}(F16, %para592)    #(TypeTypeNoShape, Tensor(F16)[64, 20, 2]) #scope: Default/network-WithLossCell/_backbone-BaseModel/transform-STN_ON/tps-TPSSpatialTransformer
      # In file /home/mindspore/lby_spencer/svtr_mindspore/svtr_mindspore/modeling/transforms/tps_spatical_transformer.py:147/    def construct(self, input, source_control_points):/#[CNode]123
    %2 : I64NoShape = Primitive::getattr{prim_type=1}(%1, "ndim")    #(Tensor(F16)[64, 20, 2], StringNoShape) #scope: Default/network-WithLossCell/_backbone-BaseModel/transform-STN_ON/tps-TPSSpatialTransformer
      # In file /home/mindspore/lby_spencer/svtr_mindspore/svtr_mindspore/modeling/transforms/tps_spatical_transformer.py:148/        assert source_control_points.ndim == 3/#[CNode]124
    %3 : BoolNoShape = DoSignaturePrimitive::S-Prim-equal{prim_type=1}(%2, I64(3))    #(I64NoShape, I64NoShape) #scope: Default/network-WithLossCell/_backbone-BaseModel/transform-STN_ON/tps-TPSSpatialTransformer
      # In file /home/mindspore/lby_spencer/svtr_mindspore/svtr_mindspore/modeling/transforms/tps_spatical_transformer.py:148/        assert source_control_points.ndim == 3/#[CNode]125
    %4 : BoolNoShape = FuncGraph::fg_10(%3)    #(BoolNoShape)    # fg_10=bool_.10 #scope: Default/network-WithLossCell/_backbone-BaseModel/transform-STN_ON/tps-TPSSpatialTransformer
      # In file /home/mindspore/lby_spencer/svtr_mindspore/svtr_mindspore/modeling/transforms/tps_spatical_transformer.py:148/        assert source_control_points.ndim == 3/#[CNode]126
    %5 : FuncNoShape = Primitive::Switch{prim_type=1}(%4, FuncGraph::fg_43, FuncGraph::fg_127)    #(BoolNoShape, FuncNoShape, FuncNoShape)    # fg_43=42.43, fg_127=128.127 #scope: Default/network-WithLossCell/_backbone-BaseModel/transform-STN_ON/tps-TPSSpatialTransformer
      # In file /home/mindspore/lby_spencer/svtr_mindspore/svtr_mindspore/modeling/transforms/tps_spatical_transformer.py:148/        assert source_control_points.ndim == 3/#[CNode]129

#------------------------> 8
    %6 = %5() #scope: Default/network-WithLossCell/_backbone-BaseModel/transform-STN_ON/tps-TPSSpatialTransformer
      # In file /home/mindspore/lby_spencer/svtr_mindspore/svtr_mindspore/modeling/transforms/tps_spatical_transformer.py:148/        assert source_control_points.ndim == 3/#[CNode]130
    Primitive::Return{prim_type=1}(%6)    #(Undefined) #scope: Default/network-WithLossCell/_backbone-BaseModel/transform-STN_ON/tps-TPSSpatialTransformer
      # In file /home/mindspore/lby_spencer/svtr_mindspore/svtr_mindspore/modeling/transforms/tps_spatical_transformer.py:148/        assert source_control_points.ndim == 3/#[CNode]131
}
# order:
#   1: @TPSSpatialTransformer.41:[CNode]132{[0]: ValueNode<Primitive> MixedPrecisionCast, [1]: ValueNode<Float> Float16, [2]: ValueNode<Tensor> Tensor(shape=[3, 2], dtype=Float32, value=
[[ 0.00000000e+00  0.00000000e+00]
 [ 0.00000000e+00  0.00000000e+00]
 [ 0.00000000e+00  0.00000000e+00]])}
#   2: @TPSSpatialTransformer.41:[CNode]133{[0]: ValueNode<Primitive> MixedPrecisionCast, [1]: ValueNode<Float> Float16, [2]: ValueNode<Tensor> Tensor(shape=[23, 23], dtype=Float64, value=[...])}
#   3: @TPSSpatialTransformer.41:[CNode]134{[0]: ValueNode<Primitive> MixedPrecisionCast, [1]: ValueNode<Float> Float16, [2]: ValueNode<Tensor> Tensor(shape=[3200, 23], dtype=Float32, value=[...])}
#   4: @TPSSpatialTransformer.41:[CNode]123{[0]: ValueNode<Primitive> MixedPrecisionCast, [1]: ValueNode<Float> Float16, [2]: source_control_points}
#   5: @TPSSpatialTransformer.41:[CNode]135{[0]: ValueNode<Primitive> MixedPrecisionCast, [1]: ValueNode<Float> Float16, [2]: input}
#   6: @TPSSpatialTransformer.41:[CNode]124{[0]: ValueNode<Primitive> getattr, [1]: [CNode]123, [2]: ValueNode<StringImm> ndim}
#   7: @TPSSpatialTransformer.41:[CNode]125{[0]: ValueNode<DoSignaturePrimitive> S-Prim-equal, [1]: [CNode]124, [2]: ValueNode<Int64Imm> 3}
#   8: @TPSSpatialTransformer.41:[CNode]126{[0]: ValueNode<FuncGraph> bool_.10, [1]: [CNode]125}
#   9: @TPSSpatialTransformer.41:[CNode]129{[0]: ValueNode<Primitive> Switch, [1]: [CNode]126, [2]: ValueNode<FuncGraph> 42.43, [3]: ValueNode<FuncGraph> 128.127}
#  10: @TPSSpatialTransformer.41:[CNode]130{[0]: [CNode]129}
#  11: @TPSSpatialTransformer.41:[CNode]131{[0]: ValueNode<Primitive> Return, [1]: [CNode]130}


# [No.10] 42.43
# In file /home/mindspore/lby_spencer/svtr_mindspore/svtr_mindspore/modeling/transforms/tps_spatical_transformer.py:148/        assert source_control_points.ndim == 3/
funcgraph fg_43[fg_41](
) {

#------------------------> 9
    %1 = FuncGraph::fg_45()    # fg_45=44.45 #scope: Default/network-WithLossCell/_backbone-BaseModel/transform-STN_ON/tps-TPSSpatialTransformer
      # In file /home/mindspore/lby_spencer/svtr_mindspore/svtr_mindspore/modeling/transforms/tps_spatical_transformer.py:148/        assert source_control_points.ndim == 3/#[CNode]136
    Primitive::Return{prim_type=1}(%1)    #(Undefined) #scope: Default/network-WithLossCell/_backbone-BaseModel/transform-STN_ON/tps-TPSSpatialTransformer
      # In file /home/mindspore/lby_spencer/svtr_mindspore/svtr_mindspore/modeling/transforms/tps_spatical_transformer.py:148/        assert source_control_points.ndim == 3/#[CNode]137
}
# order:
#   1: @42.43:[CNode]136{[0]: ValueNode<FuncGraph> 44.45}
#   2: @42.43:[CNode]137{[0]: ValueNode<Primitive> Return, [1]: [CNode]136}


# [No.11] 44.45
# In file /home/mindspore/lby_spencer/svtr_mindspore/svtr_mindspore/modeling/transforms/tps_spatical_transformer.py:148/        assert source_control_points.ndim == 3/
funcgraph fg_45[fg_41](
) {
    %1 : $(TPSSpatialTransformer.41):Tensor(F16)[64, 20, 2] = Primitive::MixedPrecisionCast{prim_type=1}(F16, %para592)    #(TypeTypeNoShape, Tensor(F16)[64, 20, 2]) #scope: Default/network-WithLossCell/_backbone-BaseModel/transform-STN_ON/tps-TPSSpatialTransformer
      # In file /home/mindspore/lby_spencer/svtr_mindspore/svtr_mindspore/modeling/transforms/tps_spatical_transformer.py:147/    def construct(self, input, source_control_points):/#[CNode]123
    %2 : Tuple[I64*3]TupleShape(NoShape, NoShape, NoShape) = Primitive::getattr{prim_type=1}(%1, "shape")    #(Tensor(F16)[64, 20, 2], StringNoShape) #scope: Default/network-WithLossCell/_backbone-BaseModel/transform-STN_ON/tps-TPSSpatialTransformer
      # In file /home/mindspore/lby_spencer/svtr_mindspore/svtr_mindspore/modeling/transforms/tps_spatical_transformer.py:149/        assert source_control_points.shape[1] == self.num_control_points/#[CNode]138
    %3 : I64NoShape = DoSignaturePrimitive::S-Prim-getitem{prim_type=1}(%2, I64(1))    #(Tuple[I64*3]TupleShape(NoShape, NoShape, NoShape), I64NoShape) #scope: Default/network-WithLossCell/_backbone-BaseModel/transform-STN_ON/tps-TPSSpatialTransformer
      # In file /home/mindspore/lby_spencer/svtr_mindspore/svtr_mindspore/modeling/transforms/tps_spatical_transformer.py:149/        assert source_control_points.shape[1] == self.num_control_points/#[CNode]139
    %4 : BoolNoShape = DoSignaturePrimitive::S-Prim-equal{prim_type=1}(%3, I64(20))    #(I64NoShape, I64NoShape) #scope: Default/network-WithLossCell/_backbone-BaseModel/transform-STN_ON/tps-TPSSpatialTransformer
      # In file /home/mindspore/lby_spencer/svtr_mindspore/svtr_mindspore/modeling/transforms/tps_spatical_transformer.py:149/        assert source_control_points.shape[1] == self.num_control_points/#[CNode]140
    %5 : BoolNoShape = FuncGraph::fg_10(%4)    #(BoolNoShape)    # fg_10=bool_.10 #scope: Default/network-WithLossCell/_backbone-BaseModel/transform-STN_ON/tps-TPSSpatialTransformer
      # In file /home/mindspore/lby_spencer/svtr_mindspore/svtr_mindspore/modeling/transforms/tps_spatical_transformer.py:149/        assert source_control_points.shape[1] == self.num_control_points/#[CNode]141
    %6 : FuncNoShape = Primitive::Switch{prim_type=1}(%5, FuncGraph::fg_47, FuncGraph::fg_142)    #(BoolNoShape, FuncNoShape, FuncNoShape)    # fg_47=46.47, fg_142=143.142 #scope: Default/network-WithLossCell/_backbone-BaseModel/transform-STN_ON/tps-TPSSpatialTransformer
      # In file /home/mindspore/lby_spencer/svtr_mindspore/svtr_mindspore/modeling/transforms/tps_spatical_transformer.py:149/        assert source_control_points.shape[1] == self.num_control_points/#[CNode]144

#------------------------> 10
    %7 = %6() #scope: Default/network-WithLossCell/_backbone-BaseModel/transform-STN_ON/tps-TPSSpatialTransformer
      # In file /home/mindspore/lby_spencer/svtr_mindspore/svtr_mindspore/modeling/transforms/tps_spatical_transformer.py:149/        assert source_control_points.shape[1] == self.num_control_points/#[CNode]145
    Primitive::Return{prim_type=1}(%7)    #(Undefined) #scope: Default/network-WithLossCell/_backbone-BaseModel/transform-STN_ON/tps-TPSSpatialTransformer
      # In file /home/mindspore/lby_spencer/svtr_mindspore/svtr_mindspore/modeling/transforms/tps_spatical_transformer.py:149/        assert source_control_points.shape[1] == self.num_control_points/#[CNode]146
}
# order:
#   1: @44.45:[CNode]138{[0]: ValueNode<Primitive> getattr, [1]: [CNode]123, [2]: ValueNode<StringImm> shape}
#   2: @44.45:[CNode]139{[0]: ValueNode<DoSignaturePrimitive> S-Prim-getitem, [1]: [CNode]138, [2]: ValueNode<Int64Imm> 1}
#   3: @44.45:[CNode]140{[0]: ValueNode<DoSignaturePrimitive> S-Prim-equal, [1]: [CNode]139, [2]: ValueNode<Int64Imm> 20}
#   4: @44.45:[CNode]141{[0]: ValueNode<FuncGraph> bool_.10, [1]: [CNode]140}
#   5: @44.45:[CNode]144{[0]: ValueNode<Primitive> Switch, [1]: [CNode]141, [2]: ValueNode<FuncGraph> 46.47, [3]: ValueNode<FuncGraph> 143.142}
#   6: @44.45:[CNode]145{[0]: [CNode]144}
#   7: @44.45:[CNode]146{[0]: ValueNode<Primitive> Return, [1]: [CNode]145}


# [No.12] 46.47
# In file /home/mindspore/lby_spencer/svtr_mindspore/svtr_mindspore/modeling/transforms/tps_spatical_transformer.py:149/        assert source_control_points.shape[1] == self.num_control_points/
funcgraph fg_47[fg_41](
) {

#------------------------> 11
    %1 = FuncGraph::fg_49()    # fg_49=48.49 #scope: Default/network-WithLossCell/_backbone-BaseModel/transform-STN_ON/tps-TPSSpatialTransformer
      # In file /home/mindspore/lby_spencer/svtr_mindspore/svtr_mindspore/modeling/transforms/tps_spatical_transformer.py:149/        assert source_control_points.shape[1] == self.num_control_points/#[CNode]147
    Primitive::Return{prim_type=1}(%1)    #(Undefined) #scope: Default/network-WithLossCell/_backbone-BaseModel/transform-STN_ON/tps-TPSSpatialTransformer
      # In file /home/mindspore/lby_spencer/svtr_mindspore/svtr_mindspore/modeling/transforms/tps_spatical_transformer.py:149/        assert source_control_points.shape[1] == self.num_control_points/#[CNode]148
}
# order:
#   1: @46.47:[CNode]147{[0]: ValueNode<FuncGraph> 48.49}
#   2: @46.47:[CNode]148{[0]: ValueNode<Primitive> Return, [1]: [CNode]147}


# [No.13] 48.49
# In file /home/mindspore/lby_spencer/svtr_mindspore/svtr_mindspore/modeling/transforms/tps_spatical_transformer.py:149/        assert source_control_points.shape[1] == self.num_control_points/
funcgraph fg_49[fg_41](
) {
    %1 : $(TPSSpatialTransformer.41):Tensor(F16)[64, 20, 2] = Primitive::MixedPrecisionCast{prim_type=1}(F16, %para592)    #(TypeTypeNoShape, Tensor(F16)[64, 20, 2]) #scope: Default/network-WithLossCell/_backbone-BaseModel/transform-STN_ON/tps-TPSSpatialTransformer
      # In file /home/mindspore/lby_spencer/svtr_mindspore/svtr_mindspore/modeling/transforms/tps_spatical_transformer.py:147/    def construct(self, input, source_control_points):/#[CNode]123
    %2 : Tuple[I64*3]TupleShape(NoShape, NoShape, NoShape) = Primitive::getattr{prim_type=1}(%1, "shape")    #(Tensor(F16)[64, 20, 2], StringNoShape) #scope: Default/network-WithLossCell/_backbone-BaseModel/transform-STN_ON/tps-TPSSpatialTransformer
      # In file /home/mindspore/lby_spencer/svtr_mindspore/svtr_mindspore/modeling/transforms/tps_spatical_transformer.py:150/        assert source_control_points.shape[2] == 2/#[CNode]149
    %3 : I64NoShape = DoSignaturePrimitive::S-Prim-getitem{prim_type=1}(%2, I64(2))    #(Tuple[I64*3]TupleShape(NoShape, NoShape, NoShape), I64NoShape) #scope: Default/network-WithLossCell/_backbone-BaseModel/transform-STN_ON/tps-TPSSpatialTransformer
      # In file /home/mindspore/lby_spencer/svtr_mindspore/svtr_mindspore/modeling/transforms/tps_spatical_transformer.py:150/        assert source_control_points.shape[2] == 2/#[CNode]150
    %4 : BoolNoShape = DoSignaturePrimitive::S-Prim-equal{prim_type=1}(%3, I64(2))    #(I64NoShape, I64NoShape) #scope: Default/network-WithLossCell/_backbone-BaseModel/transform-STN_ON/tps-TPSSpatialTransformer
      # In file /home/mindspore/lby_spencer/svtr_mindspore/svtr_mindspore/modeling/transforms/tps_spatical_transformer.py:150/        assert source_control_points.shape[2] == 2/#[CNode]151
    %5 : BoolNoShape = FuncGraph::fg_10(%4)    #(BoolNoShape)    # fg_10=bool_.10 #scope: Default/network-WithLossCell/_backbone-BaseModel/transform-STN_ON/tps-TPSSpatialTransformer
      # In file /home/mindspore/lby_spencer/svtr_mindspore/svtr_mindspore/modeling/transforms/tps_spatical_transformer.py:150/        assert source_control_points.shape[2] == 2/#[CNode]152
    %6 : FuncNoShape = Primitive::Switch{prim_type=1}(%5, FuncGraph::fg_51, FuncGraph::fg_153)    #(BoolNoShape, FuncNoShape, FuncNoShape)    # fg_51=50.51, fg_153=154.153 #scope: Default/network-WithLossCell/_backbone-BaseModel/transform-STN_ON/tps-TPSSpatialTransformer
      # In file /home/mindspore/lby_spencer/svtr_mindspore/svtr_mindspore/modeling/transforms/tps_spatical_transformer.py:150/        assert source_control_points.shape[2] == 2/#[CNode]155

#------------------------> 12
    %7 = %6() #scope: Default/network-WithLossCell/_backbone-BaseModel/transform-STN_ON/tps-TPSSpatialTransformer
      # In file /home/mindspore/lby_spencer/svtr_mindspore/svtr_mindspore/modeling/transforms/tps_spatical_transformer.py:150/        assert source_control_points.shape[2] == 2/#[CNode]156
    Primitive::Return{prim_type=1}(%7)    #(Undefined) #scope: Default/network-WithLossCell/_backbone-BaseModel/transform-STN_ON/tps-TPSSpatialTransformer
      # In file /home/mindspore/lby_spencer/svtr_mindspore/svtr_mindspore/modeling/transforms/tps_spatical_transformer.py:150/        assert source_control_points.shape[2] == 2/#[CNode]157
}
# order:
#   1: @48.49:[CNode]149{[0]: ValueNode<Primitive> getattr, [1]: [CNode]123, [2]: ValueNode<StringImm> shape}
#   2: @48.49:[CNode]150{[0]: ValueNode<DoSignaturePrimitive> S-Prim-getitem, [1]: [CNode]149, [2]: ValueNode<Int64Imm> 2}
#   3: @48.49:[CNode]151{[0]: ValueNode<DoSignaturePrimitive> S-Prim-equal, [1]: [CNode]150, [2]: ValueNode<Int64Imm> 2}
#   4: @48.49:[CNode]152{[0]: ValueNode<FuncGraph> bool_.10, [1]: [CNode]151}
#   5: @48.49:[CNode]155{[0]: ValueNode<Primitive> Switch, [1]: [CNode]152, [2]: ValueNode<FuncGraph> 50.51, [3]: ValueNode<FuncGraph> 154.153}
#   6: @48.49:[CNode]156{[0]: [CNode]155}
#   7: @48.49:[CNode]157{[0]: ValueNode<Primitive> Return, [1]: [CNode]156}


# [No.14] 50.51
# In file /home/mindspore/lby_spencer/svtr_mindspore/svtr_mindspore/modeling/transforms/tps_spatical_transformer.py:150/        assert source_control_points.shape[2] == 2/
funcgraph fg_51[fg_41](
) {

#------------------------> 13
    %1 = FuncGraph::fg_53()    # fg_53=52.53 #scope: Default/network-WithLossCell/_backbone-BaseModel/transform-STN_ON/tps-TPSSpatialTransformer
      # In file /home/mindspore/lby_spencer/svtr_mindspore/svtr_mindspore/modeling/transforms/tps_spatical_transformer.py:150/        assert source_control_points.shape[2] == 2/#[CNode]158
    Primitive::Return{prim_type=1}(%1)    #(Undefined) #scope: Default/network-WithLossCell/_backbone-BaseModel/transform-STN_ON/tps-TPSSpatialTransformer
      # In file /home/mindspore/lby_spencer/svtr_mindspore/svtr_mindspore/modeling/transforms/tps_spatical_transformer.py:150/        assert source_control_points.shape[2] == 2/#[CNode]159
}
# order:
#   1: @50.51:[CNode]158{[0]: ValueNode<FuncGraph> 52.53}
#   2: @50.51:[CNode]159{[0]: ValueNode<Primitive> Return, [1]: [CNode]158}


# [No.15] 52.53
# In file /home/mindspore/lby_spencer/svtr_mindspore/svtr_mindspore/modeling/transforms/tps_spatical_transformer.py:150/        assert source_control_points.shape[2] == 2/
funcgraph fg_53[fg_41](
) {
    %1 : $(TPSSpatialTransformer.41):Tensor(F16)[64, 3, 64, 256] = Primitive::MixedPrecisionCast{prim_type=1}(F16, %para591)    #(TypeTypeNoShape, Tensor(F16)[64, 3, 64, 256]) #scope: Default/network-WithLossCell/_backbone-BaseModel/transform-STN_ON/tps-TPSSpatialTransformer
      # In file /home/mindspore/lby_spencer/svtr_mindspore/svtr_mindspore/modeling/transforms/tps_spatical_transformer.py:147/    def construct(self, input, source_control_points):/#[CNode]135
    %2 : Tensor(F32)[64, 3, 64, 256] = DoSignaturePrimitive::S-Prim-Cast{prim_type=1}[output_names=["output"], input_names=["x", "dst_type"], SrcT=F32, DstT=F32, dst_type=F32](%1, F32)    #(Tensor(F16)[64, 3, 64, 256], TypeTypeNoShape) #scope: Default/network-WithLossCell/_backbone-BaseModel/transform-STN_ON/tps-TPSSpatialTransformer
      # In file /home/mindspore/lby_spencer/svtr_mindspore/svtr_mindspore/modeling/transforms/tps_spatical_transformer.py:166/        input = ops.cast(input,mindspore.float32)/#input
    %3 : $(TPSSpatialTransformer.41):Tensor(F16)[3200, 23] = Primitive::MixedPrecisionCast{prim_type=1}(F16, Tensor(43)[3200, 23])    #(TypeTypeNoShape, Tensor(F32)[3200, 23]) #scope: Default/network-WithLossCell/_backbone-BaseModel/transform-STN_ON/tps-TPSSpatialTransformer
      # In file /home/mindspore/lby_spencer/svtr_mindspore/svtr_mindspore/modeling/transforms/tps_spatical_transformer.py:158/        source_coordinate = ops.matmul(self.target_coordinate_repr,mapping_matrix)   #float32 and float32/#[CNode]134
    %4 : $(TPSSpatialTransformer.41):Tensor(F16)[23, 23] = Primitive::MixedPrecisionCast{prim_type=1}(F16, Tensor(44)[23, 23])    #(TypeTypeNoShape, Tensor(F64)[23, 23]) #scope: Default/network-WithLossCell/_backbone-BaseModel/transform-STN_ON/tps-TPSSpatialTransformer
      # In file /home/mindspore/lby_spencer/svtr_mindspore/svtr_mindspore/modeling/transforms/tps_spatical_transformer.py:156/        mapping_matrix = ops.matmul(self.inverse_kernel, Y)/#[CNode]133
    %5 : $(TPSSpatialTransformer.41):Tensor(F16)[64, 20, 2] = Primitive::MixedPrecisionCast{prim_type=1}(F16, %para592)    #(TypeTypeNoShape, Tensor(F16)[64, 20, 2]) #scope: Default/network-WithLossCell/_backbone-BaseModel/transform-STN_ON/tps-TPSSpatialTransformer
      # In file /home/mindspore/lby_spencer/svtr_mindspore/svtr_mindspore/modeling/transforms/tps_spatical_transformer.py:147/    def construct(self, input, source_control_points):/#[CNode]123
    %6 : $(TPSSpatialTransformer.41):Tensor(F16)[3, 2] = Primitive::MixedPrecisionCast{prim_type=1}(F16, Tensor(43)[3, 2])    #(TypeTypeNoShape, Tensor(F32)[3, 2]) #scope: Default/network-WithLossCell/_backbone-BaseModel/transform-STN_ON/tps-TPSSpatialTransformer
      # In file /home/mindspore/lby_spencer/svtr_mindspore/svtr_mindspore/modeling/transforms/tps_spatical_transformer.py:154/        padding_matrix = self.padding_matrix.expand_as(expand_as)/#[CNode]132
    %7 : FuncNoShape = Primitive::getattr{prim_type=1}(%6, "expand_as")    #(Tensor(F16)[3, 2], StringNoShape) #scope: Default/network-WithLossCell/_backbone-BaseModel/transform-STN_ON/tps-TPSSpatialTransformer
      # In file /home/mindspore/lby_spencer/svtr_mindspore/svtr_mindspore/modeling/transforms/tps_spatical_transformer.py:154/        padding_matrix = self.padding_matrix.expand_as(expand_as)/#[CNode]160
    %8 : Tuple[I64*3]TupleShape(NoShape, NoShape, NoShape) = FuncGraph::fg_161(%5)    #(Tensor(F16)[64, 20, 2])    # fg_161=shape.161 #scope: Default/network-WithLossCell/_backbone-BaseModel/transform-STN_ON/tps-TPSSpatialTransformer
      # In file /home/mindspore/lby_spencer/svtr_mindspore/svtr_mindspore/modeling/transforms/tps_spatical_transformer.py:151/        batch_size = ops.shape(source_control_points)[0]/#[CNode]162
    %9 : I64NoShape = DoSignaturePrimitive::S-Prim-getitem{prim_type=1}(%8, I64(0))    #(Tuple[I64*3]TupleShape(NoShape, NoShape, NoShape), I64NoShape) #scope: Default/network-WithLossCell/_backbone-BaseModel/transform-STN_ON/tps-TPSSpatialTransformer
      # In file /home/mindspore/lby_spencer/svtr_mindspore/svtr_mindspore/modeling/transforms/tps_spatical_transformer.py:151/        batch_size = ops.shape(source_control_points)[0]/#batch_size
    %10 : Tuple[I64*3]TupleShape(NoShape, NoShape, NoShape) = DoSignaturePrimitive::S-Prim-MakeTuple{prim_type=1}(%9, I64(3), I64(2))    #(I64NoShape, I64NoShape, I64NoShape) #scope: Default/network-WithLossCell/_backbone-BaseModel/transform-STN_ON/tps-TPSSpatialTransformer
      # In file /home/mindspore/lby_spencer/svtr_mindspore/svtr_mindspore/modeling/transforms/tps_spatical_transformer.py:152/        expand_as=ops.ones((batch_size,3,2),mindspore.float32)/#[CNode]163
    %11 : Tensor(F32)[64, 3, 2] = FuncGraph::fg_164(%10, F32)    #(Tuple[I64*3]TupleShape(NoShape, NoShape, NoShape), TypeTypeNoShape)    # fg_164=ones.164 #scope: Default/network-WithLossCell/_backbone-BaseModel/transform-STN_ON/tps-TPSSpatialTransformer
      # In file /home/mindspore/lby_spencer/svtr_mindspore/svtr_mindspore/modeling/transforms/tps_spatical_transformer.py:152/        expand_as=ops.ones((batch_size,3,2),mindspore.float32)/#expand_as
    %12 : Tensor(F16)[64, 3, 2] = %7(%11)    #(Tensor(F32)[64, 3, 2]) #scope: Default/network-WithLossCell/_backbone-BaseModel/transform-STN_ON/tps-TPSSpatialTransformer
      # In file /home/mindspore/lby_spencer/svtr_mindspore/svtr_mindspore/modeling/transforms/tps_spatical_transformer.py:154/        padding_matrix = self.padding_matrix.expand_as(expand_as)/#padding_matrix
    %13 : List[Tensor(F16)*2]ListShape[(64, 20, 2), (64, 3, 2)] = DoSignaturePrimitive::S-Prim-make_list{prim_type=1}(%5, %12)    #(Tensor(F16)[64, 20, 2], Tensor(F16)[64, 3, 2]) #scope: Default/network-WithLossCell/_backbone-BaseModel/transform-STN_ON/tps-TPSSpatialTransformer
      # In file /home/mindspore/lby_spencer/svtr_mindspore/svtr_mindspore/modeling/transforms/tps_spatical_transformer.py:155/        Y = ops.concat([source_control_points, padding_matrix], 1)/#[CNode]165
    %14 : Tensor(F16)[64, 23, 2] = FuncGraph::fg_166(%13, I64(1))    #(List[Tensor(F16)*2]ListShape[(64, 20, 2), (64, 3, 2)], I64NoShape)    # fg_166=concat.166 #scope: Default/network-WithLossCell/_backbone-BaseModel/transform-STN_ON/tps-TPSSpatialTransformer
      # In file /home/mindspore/lby_spencer/svtr_mindspore/svtr_mindspore/modeling/transforms/tps_spatical_transformer.py:155/        Y = ops.concat([source_control_points, padding_matrix], 1)/#Y
    %15 : Tensor(F16)[64, 23, 2] = FuncGraph::fg_167(%4, %14)    #(Tensor(F16)[23, 23], Tensor(F16)[64, 23, 2])    # fg_167=matmul.167 #scope: Default/network-WithLossCell/_backbone-BaseModel/transform-STN_ON/tps-TPSSpatialTransformer
      # In file /home/mindspore/lby_spencer/svtr_mindspore/svtr_mindspore/modeling/transforms/tps_spatical_transformer.py:156/        mapping_matrix = ops.matmul(self.inverse_kernel, Y)/#mapping_matrix
    %16 : Tensor(F16)[64, 23, 2] = DoSignaturePrimitive::S-Prim-Cast{prim_type=1}[output_names=["output"], input_names=["x", "dst_type"], SrcT=F32, DstT=F32, dst_type=F32](%15, F16)    #(Tensor(F16)[64, 23, 2], TypeTypeNoShape) #scope: Default/network-WithLossCell/_backbone-BaseModel/transform-STN_ON/tps-TPSSpatialTransformer
      # In file /home/mindspore/lby_spencer/svtr_mindspore/svtr_mindspore/modeling/transforms/tps_spatical_transformer.py:157/        mapping_matrix = ops.cast(mapping_matrix, mindspore.float16)/#mapping_matrix
    %17 : Tensor(F16)[64, 3200, 2] = FuncGraph::fg_167(%3, %16)    #(Tensor(F16)[3200, 23], Tensor(F16)[64, 23, 2])    # fg_167=matmul.167 #scope: Default/network-WithLossCell/_backbone-BaseModel/transform-STN_ON/tps-TPSSpatialTransformer
      # In file /home/mindspore/lby_spencer/svtr_mindspore/svtr_mindspore/modeling/transforms/tps_spatical_transformer.py:158/        source_coordinate = ops.matmul(self.target_coordinate_repr,mapping_matrix)   #float32 and float32/#source_coordinate
    %18 : Tuple[I64*3]TupleShape(NoShape, NoShape, NoShape) = Primitive::getattr{prim_type=1}(%17, "shape")    #(Tensor(F16)[64, 3200, 2], StringNoShape) #scope: Default/network-WithLossCell/_backbone-BaseModel/transform-STN_ON/tps-TPSSpatialTransformer
      # In file /home/mindspore/lby_spencer/svtr_mindspore/svtr_mindspore/modeling/transforms/tps_spatical_transformer.py:162/            (source_coordinate.shape[0], self.target_height, self.target_width, 2))           #TODO may not work/#[CNode]168
    %19 : I64NoShape = DoSignaturePrimitive::S-Prim-getitem{prim_type=1}(%18, I64(0))    #(Tuple[I64*3]TupleShape(NoShape, NoShape, NoShape), I64NoShape) #scope: Default/network-WithLossCell/_backbone-BaseModel/transform-STN_ON/tps-TPSSpatialTransformer
      # In file /home/mindspore/lby_spencer/svtr_mindspore/svtr_mindspore/modeling/transforms/tps_spatical_transformer.py:162/            (source_coordinate.shape[0], self.target_height, self.target_width, 2))           #TODO may not work/#[CNode]169
    %20 : Tuple[I64*4]TupleShape(NoShape, NoShape, NoShape, NoShape) = DoSignaturePrimitive::S-Prim-MakeTuple{prim_type=1}(%19, I64(32), I64(100), I64(2))    #(I64NoShape, I64NoShape, I64NoShape, I64NoShape) #scope: Default/network-WithLossCell/_backbone-BaseModel/transform-STN_ON/tps-TPSSpatialTransformer
      # In file /home/mindspore/lby_spencer/svtr_mindspore/svtr_mindspore/modeling/transforms/tps_spatical_transformer.py:162/            (source_coordinate.shape[0], self.target_height, self.target_width, 2))           #TODO may not work/#[CNode]170
    %21 : Tensor(F16)[64, 32, 100, 2] = FuncGraph::fg_171(%17, %20)    #(Tensor(F16)[64, 3200, 2], Tuple[I64*4]TupleShape(NoShape, NoShape, NoShape, NoShape))    # fg_171=reshape.171 #scope: Default/network-WithLossCell/_backbone-BaseModel/transform-STN_ON/tps-TPSSpatialTransformer
      # In file /home/mindspore/lby_spencer/svtr_mindspore/svtr_mindspore/modeling/transforms/tps_spatical_transformer.py:160/        grid = ops.reshape(/#grid
    %22 : FuncNoShape = Primitive::getattr{prim_type=1}(%21, "clip")    #(Tensor(F16)[64, 32, 100, 2], StringNoShape) #scope: Default/network-WithLossCell/_backbone-BaseModel/transform-STN_ON/tps-TPSSpatialTransformer
      # In file /home/mindspore/lby_spencer/svtr_mindspore/svtr_mindspore/modeling/transforms/tps_spatical_transformer.py:163/        grid = grid.clip(0,1)  # the source_control_points may be out of [0, 1]./#[CNode]172
    %23 : Tensor(F16)[64, 32, 100, 2] = %22(I64(0), I64(1))    #(I64NoShape, I64NoShape) #scope: Default/network-WithLossCell/_backbone-BaseModel/transform-STN_ON/tps-TPSSpatialTransformer
      # In file /home/mindspore/lby_spencer/svtr_mindspore/svtr_mindspore/modeling/transforms/tps_spatical_transformer.py:163/        grid = grid.clip(0,1)  # the source_control_points may be out of [0, 1]./#grid
    %24 : Tensor(F16)[64, 32, 100, 2] = DoSignaturePrimitive::S-Prim-mul{prim_type=1}(F32(2), %23)    #(F32NoShape, Tensor(F16)[64, 32, 100, 2]) #scope: Default/network-WithLossCell/_backbone-BaseModel/transform-STN_ON/tps-TPSSpatialTransformer
      # In file /home/mindspore/lby_spencer/svtr_mindspore/svtr_mindspore/modeling/transforms/tps_spatical_transformer.py:165/        grid = 2.0 * grid - 1.0/#[CNode]173
    %25 : Tensor(F16)[64, 32, 100, 2] = DoSignaturePrimitive::S-Prim-sub{prim_type=1}(%24, F32(1))    #(Tensor(F16)[64, 32, 100, 2], F32NoShape) #scope: Default/network-WithLossCell/_backbone-BaseModel/transform-STN_ON/tps-TPSSpatialTransformer
      # In file /home/mindspore/lby_spencer/svtr_mindspore/svtr_mindspore/modeling/transforms/tps_spatical_transformer.py:165/        grid = 2.0 * grid - 1.0/#grid
    %26 : Tuple[Tensor(F32),Tensor(F16)]TupleShape((64, 3, 64, 256), (64, 32, 100, 2)) = DoSignaturePrimitive::S-Prim-MakeTuple{prim_type=1}(%2, %25)    #(Tensor(F32)[64, 3, 64, 256], Tensor(F16)[64, 32, 100, 2]) #scope: Default/network-WithLossCell/_backbone-BaseModel/transform-STN_ON/tps-TPSSpatialTransformer
      # In file /home/mindspore/lby_spencer/svtr_mindspore/svtr_mindspore/modeling/transforms/tps_spatical_transformer.py:167/        output_maps = grid_sample(input, grid, canvas=None)/#[CNode]174
    %27 : Tuple[String]TupleShape(NoShape) = DoSignaturePrimitive::S-Prim-MakeTuple{prim_type=1}("canvas")    #(StringNoShape) #scope: Default/network-WithLossCell/_backbone-BaseModel/transform-STN_ON/tps-TPSSpatialTransformer
      # In file /home/mindspore/lby_spencer/svtr_mindspore/svtr_mindspore/modeling/transforms/tps_spatical_transformer.py:167/        output_maps = grid_sample(input, grid, canvas=None)/#[CNode]175
    %28 : Tuple[NoneType]TupleShape(NoShape) = DoSignaturePrimitive::S-Prim-MakeTuple{prim_type=1}(None)    #(NoneTypeNoShape) #scope: Default/network-WithLossCell/_backbone-BaseModel/transform-STN_ON/tps-TPSSpatialTransformer
      # In file /home/mindspore/lby_spencer/svtr_mindspore/svtr_mindspore/modeling/transforms/tps_spatical_transformer.py:167/        output_maps = grid_sample(input, grid, canvas=None)/#[CNode]176
    %29 : Dictionary[[canvas,],[None]]NoShape = DoSignaturePrimitive::S-Prim-make_dict{prim_type=1}(%27, %28)    #(Tuple[String]TupleShape(NoShape), Tuple[NoneType]TupleShape(NoShape)) #scope: Default/network-WithLossCell/_backbone-BaseModel/transform-STN_ON/tps-TPSSpatialTransformer
      # In file /home/mindspore/lby_spencer/svtr_mindspore/svtr_mindspore/modeling/transforms/tps_spatical_transformer.py:167/        output_maps = grid_sample(input, grid, canvas=None)/#[CNode]177

#------------------------> 14
    %30 = UnpackCall::unpack_call(FuncGraph::fg_178, %26, %29)    #(FuncNoShape, Tuple[Tensor(F32),Tensor(F16)]TupleShape((64, 3, 64, 256), (64, 32, 100, 2)), Dictionary[[canvas,],[None]]NoShape)    # fg_178=grid_sample.178 #scope: Default/network-WithLossCell/_backbone-BaseModel/transform-STN_ON/tps-TPSSpatialTransformer
      # In file /home/mindspore/lby_spencer/svtr_mindspore/svtr_mindspore/modeling/transforms/tps_spatical_transformer.py:167/        output_maps = grid_sample(input, grid, canvas=None)/#output_maps
    %31 = DoSignaturePrimitive::S-Prim-MakeTuple{prim_type=1}(%30, %17)    #(Undefined, Tensor(F16)[64, 3200, 2]) #scope: Default/network-WithLossCell/_backbone-BaseModel/transform-STN_ON/tps-TPSSpatialTransformer
      # In file /home/mindspore/lby_spencer/svtr_mindspore/svtr_mindspore/modeling/transforms/tps_spatical_transformer.py:168/        return output_maps, source_coordinate/#[CNode]179
    Primitive::Return{prim_type=1}(%31)    #(Undefined) #scope: Default/network-WithLossCell/_backbone-BaseModel/transform-STN_ON/tps-TPSSpatialTransformer
      # In file /home/mindspore/lby_spencer/svtr_mindspore/svtr_mindspore/modeling/transforms/tps_spatical_transformer.py:168/        return output_maps, source_coordinate/#[CNode]180
}
# order:
#   1: @52.53:[CNode]162{[0]: ValueNode<FuncGraph> shape.161, [1]: [CNode]123}
#   2: @52.53:batch_size{[0]: ValueNode<DoSignaturePrimitive> S-Prim-getitem, [1]: [CNode]162, [2]: ValueNode<Int64Imm> 0}
#   3: @52.53:[CNode]163{[0]: ValueNode<DoSignaturePrimitive> S-Prim-MakeTuple, [1]: batch_size, [2]: ValueNode<Int64Imm> 3, [3]: ValueNode<Int64Imm> 2}
#   4: @52.53:expand_as{[0]: ValueNode<FuncGraph> ones.164, [1]: [CNode]163, [2]: ValueNode<Float> Float32}
#   5: @52.53:padding_matrix{[0]: [CNode]160, [1]: expand_as}
#   6: @52.53:[CNode]165{[0]: ValueNode<DoSignaturePrimitive> S-Prim-make_list, [1]: [CNode]123, [2]: padding_matrix}
#   7: @52.53:Y{[0]: ValueNode<FuncGraph> concat.166, [1]: [CNode]165, [2]: ValueNode<Int64Imm> 1}
#   8: @52.53:mapping_matrix{[0]: ValueNode<FuncGraph> matmul.167, [1]: [CNode]133, [2]: Y}
#   9: @52.53:mapping_matrix{[0]: ValueNode<DoSignaturePrimitive> S-Prim-Cast, [1]: mapping_matrix, [2]: ValueNode<Float> Float16}
#  10: @52.53:source_coordinate{[0]: ValueNode<FuncGraph> matmul.167, [1]: [CNode]134, [2]: mapping_matrix}
#  11: @52.53:[CNode]168{[0]: ValueNode<Primitive> getattr, [1]: source_coordinate, [2]: ValueNode<StringImm> shape}
#  12: @52.53:[CNode]169{[0]: ValueNode<DoSignaturePrimitive> S-Prim-getitem, [1]: [CNode]168, [2]: ValueNode<Int64Imm> 0}
#  13: @52.53:[CNode]170{[0]: ValueNode<DoSignaturePrimitive> S-Prim-MakeTuple, [1]: [CNode]169, [2]: ValueNode<Int64Imm> 32, [3]: ValueNode<Int64Imm> 100, [4]: ValueNode<Int64Imm> 2}
#  14: @52.53:grid{[0]: ValueNode<FuncGraph> reshape.171, [1]: source_coordinate, [2]: [CNode]170}
#  15: @52.53:[CNode]172{[0]: ValueNode<Primitive> getattr, [1]: grid, [2]: ValueNode<StringImm> clip}
#  16: @52.53:grid{[0]: [CNode]172, [1]: ValueNode<Int64Imm> 0, [2]: ValueNode<Int64Imm> 1}
#  17: @52.53:[CNode]173{[0]: ValueNode<DoSignaturePrimitive> S-Prim-mul, [1]: ValueNode<FP32Imm> 2.000000, [2]: grid}
#  18: @52.53:grid{[0]: ValueNode<DoSignaturePrimitive> S-Prim-sub, [1]: [CNode]173, [2]: ValueNode<FP32Imm> 1.000000}
#  19: @52.53:input{[0]: ValueNode<DoSignaturePrimitive> S-Prim-Cast, [1]: [CNode]135, [2]: ValueNode<Float> Float32}
#  20: @52.53:[CNode]174{[0]: ValueNode<DoSignaturePrimitive> S-Prim-MakeTuple, [1]: input, [2]: grid}
#  21: @52.53:[CNode]175{[0]: ValueNode<DoSignaturePrimitive> S-Prim-MakeTuple, [1]: ValueNode<StringImm> canvas}
#  22: @52.53:[CNode]176{[0]: ValueNode<DoSignaturePrimitive> S-Prim-MakeTuple, [1]: ValueNode<None> None}
#  23: @52.53:[CNode]177{[0]: ValueNode<DoSignaturePrimitive> S-Prim-make_dict, [1]: [CNode]175, [2]: [CNode]176}
#  24: @52.53:output_maps{[0]: ValueNode<UnpackCall> unpack_call.181, [1]: ValueNode<FuncGraph> grid_sample.178, [2]: [CNode]174, [3]: [CNode]177}
#  25: @52.53:[CNode]179{[0]: ValueNode<DoSignaturePrimitive> S-Prim-MakeTuple, [1]: output_maps, [2]: source_coordinate}
#  26: @52.53:[CNode]180{[0]: ValueNode<Primitive> Return, [1]: [CNode]179}
#  27: @52.53:[CNode]160{[0]: ValueNode<Primitive> getattr, [1]: [CNode]132, [2]: ValueNode<StringImm> expand_as}


# [No.16] UnpackCall.54

funcgraph fg_54(
        %para593 : FuncNoShape    # 55
        , %para594 : Tuple[Tensor(F32),Tensor(F16)]TupleShape((64, 3, 64, 256), (64, 32, 100, 2))    # 56
        , %para595 : Dictionary[[canvas,],[None]]NoShape    # 57
    ) {
    %1 : Tensor(F32)[64, 3, 64, 256] = Primitive::TupleGetItem{prim_type=1}(%para594, I64(0))    #(Tuple[Tensor(F32),Tensor(F16)]TupleShape((64, 3, 64, 256), (64, 32, 100, 2)), I64NoShape) #scope: Default/network-WithLossCell/_backbone-BaseModel/transform-STN_ON/tps-TPSSpatialTransformer
#182
    %2 : Tensor(F16)[64, 32, 100, 2] = Primitive::TupleGetItem{prim_type=1}(%para594, I64(1))    #(Tuple[Tensor(F32),Tensor(F16)]TupleShape((64, 3, 64, 256), (64, 32, 100, 2)), I64NoShape) #scope: Default/network-WithLossCell/_backbone-BaseModel/transform-STN_ON/tps-TPSSpatialTransformer
#183
    %3 : NoneTypeNoShape = Primitive::dict_getitem{prim_type=1}(%para595, "canvas")    #(Dictionary[[canvas,],[None]]NoShape, StringNoShape) #scope: Default/network-WithLossCell/_backbone-BaseModel/transform-STN_ON/tps-TPSSpatialTransformer
#184
    %4 : Keyword[key : canvasvalue : None]NoShape = Primitive::make_keyword_arg{prim_type=1}("canvas", %3)    #(StringNoShape, NoneTypeNoShape) #scope: Default/network-WithLossCell/_backbone-BaseModel/transform-STN_ON/tps-TPSSpatialTransformer
#185

#------------------------> 15
    %5 = %para593(%1, %2, %4)    #(Tensor(F32)[64, 3, 64, 256], Tensor(F16)[64, 32, 100, 2], Keyword[key : canvasvalue : None]NoShape) #scope: Default/network-WithLossCell/_backbone-BaseModel/transform-STN_ON/tps-TPSSpatialTransformer
#186
    Primitive::Return{prim_type=1}(%5)    #(Undefined) #scope: Default/network-WithLossCell/_backbone-BaseModel/transform-STN_ON/tps-TPSSpatialTransformer
#187
}
# order:
#   1: @UnpackCall.54:186{[0]: 55, [1]: 182, [2]: 183, [3]: 185}
#   2: @UnpackCall.54:187{[0]: ValueNode<Primitive> Return, [1]: 186}


# [No.17] grid_sample.58
# In file /home/mindspore/lby_spencer/svtr_mindspore/svtr_mindspore/modeling/transforms/tps_spatical_transformer.py:57/def grid_sample(input, grid, canvas=None):/
funcgraph fg_58(
        %para596 : Tensor(F32)[64, 3, 64, 256]    # input
        , %para597 : Tensor(F16)[64, 32, 100, 2]    # grid
        , %para598 : Keyword[key : canvasvalue : None]NoShape    # canvas
    ) {
    %1 : NoneTypeNoShape = Primitive::extract_keyword_arg{prim_type=1}("canvas", %para598)    #(StringNoShape, Keyword[key : canvasvalue : None]NoShape) #scope: Default
#[CNode]188
    %2 : BoolNoShape = DoSignaturePrimitive::S-Prim-is_{prim_type=1}(%1, None)    #(NoneTypeNoShape, NoneTypeNoShape) #scope: Default/network-WithLossCell/_backbone-BaseModel/transform-STN_ON/tps-TPSSpatialTransformer
      # In file /home/mindspore/lby_spencer/svtr_mindspore/svtr_mindspore/modeling/transforms/tps_spatical_transformer.py:60/    if canvas is None:/#[CNode]189
    %3 : BoolNoShape = FuncGraph::fg_190(%2)    #(BoolNoShape)    # fg_190=bool_.190 #scope: Default/network-WithLossCell/_backbone-BaseModel/transform-STN_ON/tps-TPSSpatialTransformer
      # In file /home/mindspore/lby_spencer/svtr_mindspore/svtr_mindspore/modeling/transforms/tps_spatical_transformer.py:60/    if canvas is None:/#[CNode]191
    %4 : FuncNoShape = Primitive::Switch{prim_type=1}(%3, FuncGraph::fg_59, FuncGraph::fg_192)    #(BoolNoShape, FuncNoShape, FuncNoShape)    # fg_59=grid_sample.59, fg_192=grid_sample.192 #scope: Default/network-WithLossCell/_backbone-BaseModel/transform-STN_ON/tps-TPSSpatialTransformer
      # In file /home/mindspore/lby_spencer/svtr_mindspore/svtr_mindspore/modeling/transforms/tps_spatical_transformer.py:60/    if canvas is None:/#[CNode]193

#------------------------> 16
    %5 = %4() #scope: Default/network-WithLossCell/_backbone-BaseModel/transform-STN_ON/tps-TPSSpatialTransformer
      # In file /home/mindspore/lby_spencer/svtr_mindspore/svtr_mindspore/modeling/transforms/tps_spatical_transformer.py:60/    if canvas is None:/#[CNode]194
    Primitive::Return{prim_type=1}(%5)    #(Undefined) #scope: Default/network-WithLossCell/_backbone-BaseModel/transform-STN_ON/tps-TPSSpatialTransformer
      # In file /home/mindspore/lby_spencer/svtr_mindspore/svtr_mindspore/modeling/transforms/tps_spatical_transformer.py:60/    if canvas is None:/#[CNode]195
}
# order:
#   1: @grid_sample.58:[CNode]196{[0]: ValueNode<Primitive> getattr, [1]: input, [2]: ValueNode<StringImm> astype}
#   2: @grid_sample.58:[CNode]197{[0]: [CNode]196, [1]: ValueNode<Float> Float32}
#   3: @grid_sample.58:output{[0]: ValueNode<FuncGraph> grid_sample.198, [1]: [CNode]197, [2]: grid}
#   4: @grid_sample.58:[CNode]189{[0]: ValueNode<DoSignaturePrimitive> S-Prim-is_, [1]: [CNode]188, [2]: ValueNode<None> None}
#   5: @grid_sample.58:[CNode]191{[0]: ValueNode<FuncGraph> bool_.190, [1]: [CNode]189}
#   6: @grid_sample.58:[CNode]193{[0]: ValueNode<Primitive> Switch, [1]: [CNode]191, [2]: ValueNode<FuncGraph> grid_sample.59, [3]: ValueNode<FuncGraph> grid_sample.192}
#   7: @grid_sample.58:[CNode]194{[0]: [CNode]193}
#   8: @grid_sample.58:[CNode]195{[0]: ValueNode<Primitive> Return, [1]: [CNode]194}


# [No.18] grid_sample.59
# In file /home/mindspore/lby_spencer/svtr_mindspore/svtr_mindspore/modeling/transforms/tps_spatical_transformer.py:60/    if canvas is None:/
funcgraph fg_59[fg_58](
) {
    %1 : $(grid_sample.58):FuncNoShape = Primitive::getattr{prim_type=1}(%para596, "astype")    #(Tensor(F32)[64, 3, 64, 256], StringNoShape) #scope: Default/network-WithLossCell/_backbone-BaseModel/transform-STN_ON/tps-TPSSpatialTransformer
      # In file /home/mindspore/lby_spencer/svtr_mindspore/svtr_mindspore/modeling/transforms/tps_spatical_transformer.py:59/    output = ops.grid_sample(input.astype(mindspore.float32), grid)/#[CNode]196
    %2 : $(grid_sample.58):Tensor(F32)[64, 3, 64, 256] = %1(F32)    #(TypeTypeNoShape) #scope: Default/network-WithLossCell/_backbone-BaseModel/transform-STN_ON/tps-TPSSpatialTransformer
      # In file /home/mindspore/lby_spencer/svtr_mindspore/svtr_mindspore/modeling/transforms/tps_spatical_transformer.py:59/    output = ops.grid_sample(input.astype(mindspore.float32), grid)/#[CNode]197

#------------------------> 17
    %3 = $(grid_sample.58):FuncGraph::fg_198(%2, %para597)    #(Tensor(F32)[64, 3, 64, 256], Tensor(F16)[64, 32, 100, 2])    # fg_198=grid_sample.198 #scope: Default/network-WithLossCell/_backbone-BaseModel/transform-STN_ON/tps-TPSSpatialTransformer
      # In file /home/mindspore/lby_spencer/svtr_mindspore/svtr_mindspore/modeling/transforms/tps_spatical_transformer.py:59/    output = ops.grid_sample(input.astype(mindspore.float32), grid)/#output
    Primitive::Return{prim_type=1}(%3)    #(Undefined) #scope: Default/network-WithLossCell/_backbone-BaseModel/transform-STN_ON/tps-TPSSpatialTransformer
      # In file /home/mindspore/lby_spencer/svtr_mindspore/svtr_mindspore/modeling/transforms/tps_spatical_transformer.py:61/        return output/#[CNode]199
}
# order:
#   1: @grid_sample.59:[CNode]199{[0]: ValueNode<Primitive> Return, [1]: output}


# [No.19] grid_sample.60
# In file /home/mindspore/anaconda3/envs/ms1.9/lib/python3.7/site-packages/mindspore/ops/function/nn_func.py:2076/def grid_sample(input_x, grid, interpolation_mode='bilinear', padding_mode='zeros', align_corners=False):/
funcgraph fg_60(
        %para599 : Tensor(F32)[64, 3, 64, 256]    # input_x
        , %para600 : Tensor(F16)[64, 32, 100, 2]    # grid
    ) {
    %1 : I64NoShape = Primitive::getattr{prim_type=1}(%para599, "ndim")    #(Tensor(F32)[64, 3, 64, 256], StringNoShape) #scope: Default/network-WithLossCell/_backbone-BaseModel/transform-STN_ON/tps-TPSSpatialTransformer
      # In file /home/mindspore/anaconda3/envs/ms1.9/lib/python3.7/site-packages/mindspore/ops/function/nn_func.py:2148/    if input_x.ndim == 4:/#[CNode]200
    %2 : BoolNoShape = DoSignaturePrimitive::S-Prim-equal{prim_type=1}(%1, I64(4))    #(I64NoShape, I64NoShape) #scope: Default/network-WithLossCell/_backbone-BaseModel/transform-STN_ON/tps-TPSSpatialTransformer
      # In file /home/mindspore/anaconda3/envs/ms1.9/lib/python3.7/site-packages/mindspore/ops/function/nn_func.py:2148/    if input_x.ndim == 4:/#[CNode]201
    %3 : BoolNoShape = FuncGraph::fg_202(%2)    #(BoolNoShape)    # fg_202=bool_.202 #scope: Default/network-WithLossCell/_backbone-BaseModel/transform-STN_ON/tps-TPSSpatialTransformer
      # In file /home/mindspore/anaconda3/envs/ms1.9/lib/python3.7/site-packages/mindspore/ops/function/nn_func.py:2148/    if input_x.ndim == 4:/#[CNode]203
    %4 : FuncNoShape = Primitive::Switch{prim_type=1}(%3, FuncGraph::fg_61, FuncGraph::fg_204)    #(BoolNoShape, FuncNoShape, FuncNoShape)    # fg_61=grid_sample.61, fg_204=grid_sample.204 #scope: Default/network-WithLossCell/_backbone-BaseModel/transform-STN_ON/tps-TPSSpatialTransformer
      # In file /home/mindspore/anaconda3/envs/ms1.9/lib/python3.7/site-packages/mindspore/ops/function/nn_func.py:2148/    if input_x.ndim == 4:/#[CNode]205

#------------------------> 18
    %5 = %4() #scope: Default/network-WithLossCell/_backbone-BaseModel/transform-STN_ON/tps-TPSSpatialTransformer
      # In file /home/mindspore/anaconda3/envs/ms1.9/lib/python3.7/site-packages/mindspore/ops/function/nn_func.py:2148/    if input_x.ndim == 4:/#[CNode]206
    Primitive::Return{prim_type=1}(%5)    #(Undefined) #scope: Default/network-WithLossCell/_backbone-BaseModel/transform-STN_ON/tps-TPSSpatialTransformer
      # In file /home/mindspore/anaconda3/envs/ms1.9/lib/python3.7/site-packages/mindspore/ops/function/nn_func.py:2148/    if input_x.ndim == 4:/#[CNode]207
}
# order:
#   1: @grid_sample.60:[CNode]200{[0]: ValueNode<Primitive> getattr, [1]: input_x, [2]: ValueNode<StringImm> ndim}
#   2: @grid_sample.60:[CNode]201{[0]: ValueNode<DoSignaturePrimitive> S-Prim-equal, [1]: [CNode]200, [2]: ValueNode<Int64Imm> 4}
#   3: @grid_sample.60:[CNode]203{[0]: ValueNode<FuncGraph> bool_.202, [1]: [CNode]201}
#   4: @grid_sample.60:[CNode]205{[0]: ValueNode<Primitive> Switch, [1]: [CNode]203, [2]: ValueNode<FuncGraph> grid_sample.61, [3]: ValueNode<FuncGraph> grid_sample.204}
#   5: @grid_sample.60:[CNode]206{[0]: [CNode]205}
#   6: @grid_sample.60:[CNode]207{[0]: ValueNode<Primitive> Return, [1]: [CNode]206}


# [No.20] grid_sample.61
# In file /home/mindspore/anaconda3/envs/ms1.9/lib/python3.7/site-packages/mindspore/ops/function/nn_func.py:2148/    if input_x.ndim == 4:/
funcgraph fg_61[fg_60](
) {
    %1 : FuncNoShape = FuncGraph::fg_208(ClassType)    #(FuncNoShape)    # fg_208=_get_cache_prim.208 #scope: Default/network-WithLossCell/_backbone-BaseModel/transform-STN_ON/tps-TPSSpatialTransformer
      # In file /home/mindspore/anaconda3/envs/ms1.9/lib/python3.7/site-packages/mindspore/ops/function/nn_func.py:2149/        _grid_sampler_2d = _get_cache_prim(NN_OPS.GridSampler2D)(interpolation_mode, padding_mode, align_corners)/#[CNode]209
    %2 : FuncNoShape = %1("bilinear", "zeros", Bool(0))    #(StringNoShape, StringNoShape, BoolNoShape) #scope: Default/network-WithLossCell/_backbone-BaseModel/transform-STN_ON/tps-TPSSpatialTransformer
      # In file /home/mindspore/anaconda3/envs/ms1.9/lib/python3.7/site-packages/mindspore/ops/function/nn_func.py:2149/        _grid_sampler_2d = _get_cache_prim(NN_OPS.GridSampler2D)(interpolation_mode, padding_mode, align_corners)/#_grid_sampler_2d

#------------------------> 19
    %3 = %2(%para599, %para600)    #(Tensor(F32)[64, 3, 64, 256], Tensor(F16)[64, 32, 100, 2]) #scope: Default/network-WithLossCell/_backbone-BaseModel/transform-STN_ON/tps-TPSSpatialTransformer
      # In file /home/mindspore/anaconda3/envs/ms1.9/lib/python3.7/site-packages/mindspore/ops/function/nn_func.py:2150/        return _grid_sampler_2d(input_x, grid)/#[CNode]210
    Primitive::Return{prim_type=1}(%3)    #(Undefined) #scope: Default/network-WithLossCell/_backbone-BaseModel/transform-STN_ON/tps-TPSSpatialTransformer
      # In file /home/mindspore/anaconda3/envs/ms1.9/lib/python3.7/site-packages/mindspore/ops/function/nn_func.py:2150/        return _grid_sampler_2d(input_x, grid)/#[CNode]211
}
# order:
#   1: @grid_sample.61:[CNode]209{[0]: ValueNode<FuncGraph> _get_cache_prim.208, [1]: ValueNode<ClassType> class 'mindspore.ops.operations.nn_ops.GridSampler2D'}
#   2: @grid_sample.61:_grid_sampler_2d{[0]: [CNode]209, [1]: ValueNode<StringImm> bilinear, [2]: ValueNode<StringImm> zeros, [3]: ValueNode<BoolImm> false}
#   3: @grid_sample.61:[CNode]210{[0]: _grid_sampler_2d, [1]: input_x, [2]: grid}
#   4: @grid_sample.61:[CNode]211{[0]: ValueNode<Primitive> Return, [1]: [CNode]210}


#===============================================================================
# num of function graphs in stack: 20/21 (Ignored 1 internal frames).
